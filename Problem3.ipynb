{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "7dde36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import preprocessing \n",
    "import torch.optim as optim\n",
    "import torch.nn as neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "b3f3cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = pd.read_csv(\"C:\\\\Users\\\\dhruv\\\\Downloads\\\\Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "3cda4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=DS.sample(frac=0.8,random_state=0) \n",
    "test=DS.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "c6c51b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1820000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1767150</td>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1750000</td>\n",
       "      <td>3620</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1750000</td>\n",
       "      <td>2910</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1750000</td>\n",
       "      <td>3850</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>unfurnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0    13300000  7420         4          2        3      yes        no       no   \n",
       "1    12250000  8960         4          4        4      yes        no       no   \n",
       "2    12250000  9960         3          2        2      yes        no      yes   \n",
       "3    12215000  7500         4          2        2      yes        no      yes   \n",
       "4    11410000  7420         4          1        2      yes       yes      yes   \n",
       "..        ...   ...       ...        ...      ...      ...       ...      ...   \n",
       "540   1820000  3000         2          1        1      yes        no      yes   \n",
       "541   1767150  2400         3          1        1       no        no       no   \n",
       "542   1750000  3620         2          1        1      yes        no       no   \n",
       "543   1750000  2910         3          1        1       no        no       no   \n",
       "544   1750000  3850         3          1        2      yes        no       no   \n",
       "\n",
       "    hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0                no             yes        2      yes        furnished  \n",
       "1                no             yes        3       no        furnished  \n",
       "2                no              no        2      yes   semi-furnished  \n",
       "3                no             yes        3      yes        furnished  \n",
       "4                no             yes        2       no        furnished  \n",
       "..              ...             ...      ...      ...              ...  \n",
       "540              no              no        2       no      unfurnished  \n",
       "541              no              no        0       no   semi-furnished  \n",
       "542              no              no        0       no      unfurnished  \n",
       "543              no              no        0       no        furnished  \n",
       "544              no              no        0       no      unfurnished  \n",
       "\n",
       "[545 rows x 13 columns]"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "a34a6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['price','area','bedrooms','bathrooms','stories','parking']]\n",
    "test = test[['price','area','bedrooms','bathrooms','stories','parking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "fa4e0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "7926a141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.16151203, 0.4       , 0.        , 0.33333333,\n",
       "        0.33333333],\n",
       "       [0.        , 0.54776632, 0.4       , 0.        , 0.        ,\n",
       "        0.66666667],\n",
       "       [0.        , 0.12439863, 0.6       , 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.13402062, 0.4       , 0.        , 0.33333333,\n",
       "        0.33333333],\n",
       "       [0.        , 0.08247423, 0.4       , 0.33333333, 0.33333333,\n",
       "        0.        ],\n",
       "       [0.        , 0.21649485, 0.4       , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_t = np.array(train.area)\n",
    "X2_t = np.array(train.bedrooms)\n",
    "X3_t = np.array(train.bathrooms)\n",
    "X4_t = np.array(train.stories)\n",
    "X5_t = np.array(train.parking)\n",
    "\n",
    "X0_t= np.ones(436)\n",
    "\n",
    "X = np.vstack([X0_t,X1_t,X2_t,X3_t,X4_t,X5_t])\n",
    "X = X.T\n",
    "X = np.array(X)   \n",
    "x = scaler.fit_transform(X)\n",
    "X= x\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "9bd04100",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_t = np.array(train.price)\n",
    "Y = Y_t\n",
    "Y = Y_t.reshape(436,1)\n",
    "y = scaler.fit_transform(Y)\n",
    "Y=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "abe18eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights and bias column\n",
    "theta = np.array([0., 0., 0., 0., 0., 0.])\n",
    "theta = theta.reshape(6,1)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "8789866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Array\n",
    "t_c = Y #PRICE(Actual Y's or Data(price))\n",
    "t_u = X #Epochs(Actual X's ...multidimentional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "e7f0fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = torch.tensor(t_c, dtype=torch.float64)#.to_numpy()\n",
    "t_u = torch.tensor(t_u, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "f632627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c= np.array(t_c)\n",
    "t_u= np.array(t_u)\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "e3d0a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights and Bias as column\n",
    "b = torch.zeros(1)\n",
    "w5 = torch.ones(1)\n",
    "w4 = torch.ones(1)\n",
    "w3 = torch.ones(1)\n",
    "w2 = torch.ones(1)\n",
    "w1 = torch.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "6776074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [b, w1,w2, w3, w4, w5]\n",
    "theta = torch.tensor(theta).reshape(6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "699b7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model definition linear\n",
    "def model(X, theta):\n",
    "    return np.matmul(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "5bc1e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "def loss_func(t_p, t_c):\n",
    "    var = (t_p - t_c)**2\n",
    "    return var.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "db2dd3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p = model(X, theta)\n",
    "#t_p = torch.tensor(t_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "51fb3797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1408, dtype=torch.float64)"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_func(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "de148f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_del(delta):\n",
    "    b_del = [delta, 0,0,0,0,0]\n",
    "    b_del = torch.tensor(b_del).reshape(6,1)\n",
    "    return b_del\n",
    "def w5_del(delta):\n",
    "    b_del = [0, delta,0,0,0,0]\n",
    "    b_del = torch.tensor(b_del).reshape(6,1)\n",
    "    return b_del\n",
    "def w4_del(delta):\n",
    "    b_del = [0, 0,delta,0,0,0]\n",
    "    b_del = torch.tensor(b_del).reshape(6,1)\n",
    "    return b_del\n",
    "def w3_del(delta):\n",
    "    b_del = [0, 0,0,delta,0,0]\n",
    "    b_del = torch.tensor(b_del).reshape(6,1)\n",
    "    return b_del\n",
    "def w2_del(delta):\n",
    "    b_del = [0, 0,0,0,delta,0]\n",
    "    b_del = torch.tensor(b_del).reshape(6,1)\n",
    "    return b_del\n",
    "def w1_del(delta):\n",
    "    b_del = [0, 0,0,0,0,delta]\n",
    "    b_del = torch.tensor(b_del).reshape(6,1)\n",
    "    return b_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "df60b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.7\n",
    "\n",
    "loss_rate_of_change_b = (loss_func(model(t_u, theta+b_del(delta)), t_c) - \n",
    "loss_func(model(t_u, theta-b_del(delta)), t_c))/(2.0 * delta)\n",
    "\n",
    "loss_rate_of_change_w1 = (loss_func(model(t_u, theta+w1_del(delta)), t_c) - \n",
    "loss_func(model(t_u, theta-w1_del(delta)), t_c))/(2.0 * delta)\n",
    "\n",
    "loss_rate_of_change_w2 = (loss_func(model(t_u, theta+w2_del(delta)), t_c) - \n",
    "loss_func(model(t_u, theta-w2_del(delta)), t_c))/(2.0 * delta)\n",
    "\n",
    "loss_rate_of_change_w3 = (loss_func(model(t_u, theta+w3_del(delta)), t_c) - \n",
    "loss_func(model(t_u, theta-w3_del(delta)), t_c))/(2.0 * delta)\n",
    "\n",
    "loss_rate_of_change_w4 = (loss_func(model(t_u, theta+w4_del(delta)), t_c) - \n",
    "loss_func(model(t_u, theta-w4_del(delta)), t_c))/(2.0 * delta)\n",
    "\n",
    "loss_rate_of_change_w5 = (loss_func(model(t_u, theta+w5_del(delta)), t_c) - \n",
    "loss_func(model(t_u, theta-w5_del(delta)), t_c))/(2.0 * delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "ff93bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "w1 = w1 - learning_rate * loss_rate_of_change_w1\n",
    "w2 = w2 - learning_rate * loss_rate_of_change_w2\n",
    "w3 = w3 - learning_rate * loss_rate_of_change_w3\n",
    "w4 = w4 - learning_rate * loss_rate_of_change_w4\n",
    "w5 = w5 - learning_rate * loss_rate_of_change_w5\n",
    "b = b - learning_rate * loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "3e8311f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partial deriv of loss function \n",
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs=2* (t_p - t_c) / t_p.size(0)\n",
    "    return dsq_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "0b743b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm/dw5\n",
    "def dmodel_dw5(t_u, w5, w4, w3, w2, w1, b):\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "bb281697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm/dw4\n",
    "def dmodel_dw4(t_u, w5, w4, w3, w2, w1, b):\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "5a2988e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm/dw3\n",
    "def dmodel_dw3(t_u, w5, w4, w3, w2, w1, b):\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "141a1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm/dw2\n",
    "def dmodel_dw2(t_u, w5, w4, w3, w2, w1, b):\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "9fdfdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm/dw1\n",
    "def dmodel_dw1(t_u, w5, w4, w3, w2, w1, b):\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "57e2e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm/db\n",
    "def dmodel_db(t_u, w5, w4, w3, w2, w1, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "dabd3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(t_u, t_c, t_p, w5, w4, w3, w2, w1, b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw5 = dloss_dtp * dmodel_dw2(t_u, w5, w4, w3, w2, w1, b)\n",
    "    dloss_dw4 = dloss_dtp * dmodel_dw1(t_u, w5, w4, w3, w2, w1, b)\n",
    "    dloss_dw3 = dloss_dtp * dmodel_db(t_u, w5, w4, w3, w2, w1, b)\n",
    "    dloss_dw2 = dloss_dtp * dmodel_dw2(t_u, w5, w4, w3, w2, w1, b)\n",
    "    dloss_dw1 = dloss_dtp * dmodel_dw1(t_u, w5, w4, w3, w2, w1, b)\n",
    "    dloss_db = dloss_dtp * dmodel_db(t_u, w5, w4, w3, w2, w1, b)\n",
    "    return torch.stack([dloss_dw5.sum(), dloss_dw4.sum(), dloss_dw3.sum(), dloss_dw2.sum(), dloss_dw1.sum(), dloss_db.sum()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "4bb9ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w5, w4, w3, w2, w1, b = params\n",
    "        theta = [b, w1,w2, w3, w4, w5]\n",
    "        theta = torch.tensor(theta).reshape(6,1)\n",
    "        t_p = model(t_u, theta)\n",
    "        loss = loss_func(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w5, w4, w3, w2, w1, b)\n",
    "        params = params - learning_rate * grad\n",
    "        print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "        print('Params: %f', params)\n",
    "        print(\"Grad: %f\", grad)\n",
    "        print('-------------------------------------------------')\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "5bbcb03e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 0.454918\n",
      "Params: %f tensor([0.9998, 0.9998, 0.9999, 0.4998, 0.0998, 0.4999], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7521, 1.7521, 1.0286, 1.7521, 1.7521, 1.0286], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 2, Loss 0.454624\n",
      "Params: %f tensor([0.9996, 0.9996, 0.9998, 0.4996, 0.0996, 0.4998], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7515, 1.7515, 1.0282, 1.7515, 1.7515, 1.0282], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 3, Loss 0.454331\n",
      "Params: %f tensor([0.9995, 0.9995, 0.9997, 0.4995, 0.0995, 0.4997], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7509, 1.7509, 1.0278, 1.7509, 1.7509, 1.0278], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 4, Loss 0.454038\n",
      "Params: %f tensor([0.9993, 0.9993, 0.9996, 0.4993, 0.0993, 0.4996], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7502, 1.7502, 1.0274, 1.7502, 1.7502, 1.0274], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 5, Loss 0.453745\n",
      "Params: %f tensor([0.9991, 0.9991, 0.9995, 0.4991, 0.0991, 0.4995], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7496, 1.7496, 1.0270, 1.7496, 1.7496, 1.0270], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 6, Loss 0.453452\n",
      "Params: %f tensor([0.9989, 0.9989, 0.9994, 0.4989, 0.0989, 0.4994], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7490, 1.7490, 1.0265, 1.7490, 1.7490, 1.0265], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 7, Loss 0.453160\n",
      "Params: %f tensor([0.9988, 0.9988, 0.9993, 0.4988, 0.0988, 0.4993], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7483, 1.7483, 1.0261, 1.7483, 1.7483, 1.0261], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 8, Loss 0.452868\n",
      "Params: %f tensor([0.9986, 0.9986, 0.9992, 0.4986, 0.0986, 0.4992], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7477, 1.7477, 1.0257, 1.7477, 1.7477, 1.0257], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 9, Loss 0.452575\n",
      "Params: %f tensor([0.9984, 0.9984, 0.9991, 0.4984, 0.0984, 0.4991], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7471, 1.7471, 1.0253, 1.7471, 1.7471, 1.0253], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 10, Loss 0.452284\n",
      "Params: %f tensor([0.9983, 0.9983, 0.9990, 0.4983, 0.0983, 0.4990], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7464, 1.7464, 1.0249, 1.7464, 1.7464, 1.0249], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 11, Loss 0.451992\n",
      "Params: %f tensor([0.9981, 0.9981, 0.9989, 0.4981, 0.0981, 0.4989], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7458, 1.7458, 1.0245, 1.7458, 1.7458, 1.0245], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 12, Loss 0.451701\n",
      "Params: %f tensor([0.9979, 0.9979, 0.9988, 0.4979, 0.0979, 0.4988], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7452, 1.7452, 1.0241, 1.7452, 1.7452, 1.0241], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 13, Loss 0.451409\n",
      "Params: %f tensor([0.9977, 0.9977, 0.9987, 0.4977, 0.0977, 0.4987], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7445, 1.7445, 1.0237, 1.7445, 1.7445, 1.0237], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 14, Loss 0.451118\n",
      "Params: %f tensor([0.9976, 0.9976, 0.9986, 0.4976, 0.0976, 0.4986], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7439, 1.7439, 1.0233, 1.7439, 1.7439, 1.0233], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 15, Loss 0.450828\n",
      "Params: %f tensor([0.9974, 0.9974, 0.9985, 0.4974, 0.0974, 0.4985], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7433, 1.7433, 1.0228, 1.7433, 1.7433, 1.0228], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 16, Loss 0.450537\n",
      "Params: %f tensor([0.9972, 0.9972, 0.9984, 0.4972, 0.0972, 0.4984], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7426, 1.7426, 1.0224, 1.7426, 1.7426, 1.0224], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 17, Loss 0.450247\n",
      "Params: %f tensor([0.9970, 0.9970, 0.9983, 0.4970, 0.0970, 0.4983], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7420, 1.7420, 1.0220, 1.7420, 1.7420, 1.0220], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 18, Loss 0.449957\n",
      "Params: %f tensor([0.9969, 0.9969, 0.9982, 0.4969, 0.0969, 0.4982], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7414, 1.7414, 1.0216, 1.7414, 1.7414, 1.0216], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 19, Loss 0.449667\n",
      "Params: %f tensor([0.9967, 0.9967, 0.9981, 0.4967, 0.0967, 0.4981], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7407, 1.7407, 1.0212, 1.7407, 1.7407, 1.0212], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 20, Loss 0.449377\n",
      "Params: %f tensor([0.9965, 0.9965, 0.9980, 0.4965, 0.0965, 0.4980], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7401, 1.7401, 1.0208, 1.7401, 1.7401, 1.0208], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 21, Loss 0.449087\n",
      "Params: %f tensor([0.9963, 0.9963, 0.9978, 0.4963, 0.0963, 0.4978], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7395, 1.7395, 1.0204, 1.7395, 1.7395, 1.0204], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 22, Loss 0.448798\n",
      "Params: %f tensor([0.9962, 0.9962, 0.9977, 0.4962, 0.0962, 0.4977], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7389, 1.7389, 1.0200, 1.7389, 1.7389, 1.0200], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 23, Loss 0.448509\n",
      "Params: %f tensor([0.9960, 0.9960, 0.9976, 0.4960, 0.0960, 0.4976], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7382, 1.7382, 1.0196, 1.7382, 1.7382, 1.0196], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 24, Loss 0.448220\n",
      "Params: %f tensor([0.9958, 0.9958, 0.9975, 0.4958, 0.0958, 0.4975], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7376, 1.7376, 1.0192, 1.7376, 1.7376, 1.0192], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 25, Loss 0.447931\n",
      "Params: %f tensor([0.9956, 0.9956, 0.9974, 0.4956, 0.0956, 0.4974], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7370, 1.7370, 1.0187, 1.7370, 1.7370, 1.0187], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 26, Loss 0.447643\n",
      "Params: %f tensor([0.9955, 0.9955, 0.9973, 0.4955, 0.0955, 0.4973], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7363, 1.7363, 1.0183, 1.7363, 1.7363, 1.0183], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 27, Loss 0.447355\n",
      "Params: %f tensor([0.9953, 0.9953, 0.9972, 0.4953, 0.0953, 0.4972], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7357, 1.7357, 1.0179, 1.7357, 1.7357, 1.0179], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 28, Loss 0.447067\n",
      "Params: %f tensor([0.9951, 0.9951, 0.9971, 0.4951, 0.0951, 0.4971], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7351, 1.7351, 1.0175, 1.7351, 1.7351, 1.0175], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 29, Loss 0.446779\n",
      "Params: %f tensor([0.9949, 0.9949, 0.9970, 0.4949, 0.0949, 0.4970], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7345, 1.7345, 1.0171, 1.7345, 1.7345, 1.0171], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 30, Loss 0.446491\n",
      "Params: %f tensor([0.9948, 0.9948, 0.9969, 0.4948, 0.0948, 0.4969], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7338, 1.7338, 1.0167, 1.7338, 1.7338, 1.0167], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 31, Loss 0.446204\n",
      "Params: %f tensor([0.9946, 0.9946, 0.9968, 0.4946, 0.0946, 0.4968], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7332, 1.7332, 1.0163, 1.7332, 1.7332, 1.0163], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 32, Loss 0.445917\n",
      "Params: %f tensor([0.9944, 0.9944, 0.9967, 0.4944, 0.0944, 0.4967], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7326, 1.7326, 1.0159, 1.7326, 1.7326, 1.0159], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 33, Loss 0.445630\n",
      "Params: %f tensor([0.9943, 0.9943, 0.9966, 0.4943, 0.0943, 0.4966], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7319, 1.7319, 1.0155, 1.7319, 1.7319, 1.0155], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 34, Loss 0.445343\n",
      "Params: %f tensor([0.9941, 0.9941, 0.9965, 0.4941, 0.0941, 0.4965], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7313, 1.7313, 1.0151, 1.7313, 1.7313, 1.0151], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 35, Loss 0.445056\n",
      "Params: %f tensor([0.9939, 0.9939, 0.9964, 0.4939, 0.0939, 0.4964], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7307, 1.7307, 1.0147, 1.7307, 1.7307, 1.0147], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 36, Loss 0.444770\n",
      "Params: %f tensor([0.9937, 0.9937, 0.9963, 0.4937, 0.0937, 0.4963], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7301, 1.7301, 1.0143, 1.7301, 1.7301, 1.0143], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 37, Loss 0.444484\n",
      "Params: %f tensor([0.9936, 0.9936, 0.9962, 0.4936, 0.0936, 0.4962], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7294, 1.7294, 1.0139, 1.7294, 1.7294, 1.0139], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 38, Loss 0.444198\n",
      "Params: %f tensor([0.9934, 0.9934, 0.9961, 0.4934, 0.0934, 0.4961], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7288, 1.7288, 1.0134, 1.7288, 1.7288, 1.0134], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 39, Loss 0.443912\n",
      "Params: %f tensor([0.9932, 0.9932, 0.9960, 0.4932, 0.0932, 0.4960], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7282, 1.7282, 1.0130, 1.7282, 1.7282, 1.0130], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 40, Loss 0.443626\n",
      "Params: %f tensor([0.9930, 0.9930, 0.9959, 0.4930, 0.0930, 0.4959], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7276, 1.7276, 1.0126, 1.7276, 1.7276, 1.0126], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 41, Loss 0.443341\n",
      "Params: %f tensor([0.9929, 0.9929, 0.9958, 0.4929, 0.0929, 0.4958], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7269, 1.7269, 1.0122, 1.7269, 1.7269, 1.0122], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 42, Loss 0.443056\n",
      "Params: %f tensor([0.9927, 0.9927, 0.9957, 0.4927, 0.0927, 0.4957], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7263, 1.7263, 1.0118, 1.7263, 1.7263, 1.0118], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 43, Loss 0.442771\n",
      "Params: %f tensor([0.9925, 0.9925, 0.9956, 0.4925, 0.0925, 0.4956], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7257, 1.7257, 1.0114, 1.7257, 1.7257, 1.0114], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 44, Loss 0.442486\n",
      "Params: %f tensor([0.9924, 0.9924, 0.9955, 0.4924, 0.0924, 0.4955], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7251, 1.7251, 1.0110, 1.7251, 1.7251, 1.0110], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 45, Loss 0.442202\n",
      "Params: %f tensor([0.9922, 0.9922, 0.9954, 0.4922, 0.0922, 0.4954], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7244, 1.7244, 1.0106, 1.7244, 1.7244, 1.0106], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 46, Loss 0.441918\n",
      "Params: %f tensor([0.9920, 0.9920, 0.9953, 0.4920, 0.0920, 0.4953], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7238, 1.7238, 1.0102, 1.7238, 1.7238, 1.0102], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 47, Loss 0.441634\n",
      "Params: %f tensor([0.9918, 0.9918, 0.9952, 0.4918, 0.0918, 0.4952], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7232, 1.7232, 1.0098, 1.7232, 1.7232, 1.0098], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 48, Loss 0.441350\n",
      "Params: %f tensor([0.9917, 0.9917, 0.9951, 0.4917, 0.0917, 0.4951], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7226, 1.7226, 1.0094, 1.7226, 1.7226, 1.0094], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 49, Loss 0.441066\n",
      "Params: %f tensor([0.9915, 0.9915, 0.9950, 0.4915, 0.0915, 0.4950], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7219, 1.7219, 1.0090, 1.7219, 1.7219, 1.0090], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 50, Loss 0.440783\n",
      "Params: %f tensor([0.9913, 0.9913, 0.9949, 0.4913, 0.0913, 0.4949], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7213, 1.7213, 1.0086, 1.7213, 1.7213, 1.0086], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 51, Loss 0.440499\n",
      "Params: %f tensor([0.9911, 0.9911, 0.9948, 0.4911, 0.0911, 0.4948], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7207, 1.7207, 1.0082, 1.7207, 1.7207, 1.0082], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 52, Loss 0.440216\n",
      "Params: %f tensor([0.9910, 0.9910, 0.9947, 0.4910, 0.0910, 0.4947], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7201, 1.7201, 1.0078, 1.7201, 1.7201, 1.0078], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 53, Loss 0.439933\n",
      "Params: %f tensor([0.9908, 0.9908, 0.9946, 0.4908, 0.0908, 0.4946], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7194, 1.7194, 1.0074, 1.7194, 1.7194, 1.0074], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 54, Loss 0.439651\n",
      "Params: %f tensor([0.9906, 0.9906, 0.9945, 0.4906, 0.0906, 0.4945], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7188, 1.7188, 1.0070, 1.7188, 1.7188, 1.0070], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 55, Loss 0.439368\n",
      "Params: %f tensor([0.9905, 0.9905, 0.9944, 0.4905, 0.0905, 0.4944], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7182, 1.7182, 1.0065, 1.7182, 1.7182, 1.0065], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 56, Loss 0.439086\n",
      "Params: %f tensor([0.9903, 0.9903, 0.9943, 0.4903, 0.0903, 0.4943], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7176, 1.7176, 1.0061, 1.7176, 1.7176, 1.0061], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 57, Loss 0.438804\n",
      "Params: %f tensor([0.9901, 0.9901, 0.9942, 0.4901, 0.0901, 0.4942], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7170, 1.7170, 1.0057, 1.7170, 1.7170, 1.0057], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 58, Loss 0.438522\n",
      "Params: %f tensor([0.9899, 0.9899, 0.9941, 0.4899, 0.0899, 0.4941], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7163, 1.7163, 1.0053, 1.7163, 1.7163, 1.0053], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 59, Loss 0.438241\n",
      "Params: %f tensor([0.9898, 0.9898, 0.9940, 0.4898, 0.0898, 0.4940], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7157, 1.7157, 1.0049, 1.7157, 1.7157, 1.0049], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 60, Loss 0.437959\n",
      "Params: %f tensor([0.9896, 0.9896, 0.9939, 0.4896, 0.0896, 0.4939], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7151, 1.7151, 1.0045, 1.7151, 1.7151, 1.0045], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch 61, Loss 0.437678\n",
      "Params: %f tensor([0.9894, 0.9894, 0.9938, 0.4894, 0.0894, 0.4938], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7145, 1.7145, 1.0041, 1.7145, 1.7145, 1.0041], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 62, Loss 0.437397\n",
      "Params: %f tensor([0.9893, 0.9893, 0.9937, 0.4893, 0.0893, 0.4937], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7138, 1.7138, 1.0037, 1.7138, 1.7138, 1.0037], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 63, Loss 0.437116\n",
      "Params: %f tensor([0.9891, 0.9891, 0.9936, 0.4891, 0.0891, 0.4936], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7132, 1.7132, 1.0033, 1.7132, 1.7132, 1.0033], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 64, Loss 0.436836\n",
      "Params: %f tensor([0.9889, 0.9889, 0.9935, 0.4889, 0.0889, 0.4935], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7126, 1.7126, 1.0029, 1.7126, 1.7126, 1.0029], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 65, Loss 0.436555\n",
      "Params: %f tensor([0.9887, 0.9887, 0.9934, 0.4887, 0.0887, 0.4934], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7120, 1.7120, 1.0025, 1.7120, 1.7120, 1.0025], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 66, Loss 0.436275\n",
      "Params: %f tensor([0.9886, 0.9886, 0.9933, 0.4886, 0.0886, 0.4933], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7114, 1.7114, 1.0021, 1.7114, 1.7114, 1.0021], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 67, Loss 0.435995\n",
      "Params: %f tensor([0.9884, 0.9884, 0.9932, 0.4884, 0.0884, 0.4932], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7107, 1.7107, 1.0017, 1.7107, 1.7107, 1.0017], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 68, Loss 0.435715\n",
      "Params: %f tensor([0.9882, 0.9882, 0.9931, 0.4882, 0.0882, 0.4931], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7101, 1.7101, 1.0013, 1.7101, 1.7101, 1.0013], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 69, Loss 0.435436\n",
      "Params: %f tensor([0.9881, 0.9881, 0.9930, 0.4881, 0.0881, 0.4930], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7095, 1.7095, 1.0009, 1.7095, 1.7095, 1.0009], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 70, Loss 0.435157\n",
      "Params: %f tensor([0.9879, 0.9879, 0.9929, 0.4879, 0.0879, 0.4929], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7089, 1.7089, 1.0005, 1.7089, 1.7089, 1.0005], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 71, Loss 0.434877\n",
      "Params: %f tensor([0.9877, 0.9877, 0.9928, 0.4877, 0.0877, 0.4928], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7083, 1.7083, 1.0001, 1.7083, 1.7083, 1.0001], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 72, Loss 0.434598\n",
      "Params: %f tensor([0.9875, 0.9875, 0.9927, 0.4875, 0.0875, 0.4927], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7077, 1.7077, 0.9997, 1.7077, 1.7077, 0.9997], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 73, Loss 0.434320\n",
      "Params: %f tensor([0.9874, 0.9874, 0.9926, 0.4874, 0.0874, 0.4926], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7070, 1.7070, 0.9993, 1.7070, 1.7070, 0.9993], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 74, Loss 0.434041\n",
      "Params: %f tensor([0.9872, 0.9872, 0.9925, 0.4872, 0.0872, 0.4925], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7064, 1.7064, 0.9989, 1.7064, 1.7064, 0.9989], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 75, Loss 0.433763\n",
      "Params: %f tensor([0.9870, 0.9870, 0.9924, 0.4870, 0.0870, 0.4924], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7058, 1.7058, 0.9985, 1.7058, 1.7058, 0.9985], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 76, Loss 0.433485\n",
      "Params: %f tensor([0.9869, 0.9869, 0.9923, 0.4869, 0.0869, 0.4923], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7052, 1.7052, 0.9981, 1.7052, 1.7052, 0.9981], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 77, Loss 0.433207\n",
      "Params: %f tensor([0.9867, 0.9867, 0.9922, 0.4867, 0.0867, 0.4922], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7046, 1.7046, 0.9977, 1.7046, 1.7046, 0.9977], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 78, Loss 0.432929\n",
      "Params: %f tensor([0.9865, 0.9865, 0.9921, 0.4865, 0.0865, 0.4921], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7039, 1.7039, 0.9973, 1.7039, 1.7039, 0.9973], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 79, Loss 0.432651\n",
      "Params: %f tensor([0.9864, 0.9864, 0.9920, 0.4864, 0.0864, 0.4920], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7033, 1.7033, 0.9969, 1.7033, 1.7033, 0.9969], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 80, Loss 0.432374\n",
      "Params: %f tensor([0.9862, 0.9862, 0.9919, 0.4862, 0.0862, 0.4919], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7027, 1.7027, 0.9965, 1.7027, 1.7027, 0.9965], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 81, Loss 0.432097\n",
      "Params: %f tensor([0.9860, 0.9860, 0.9918, 0.4860, 0.0860, 0.4918], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7021, 1.7021, 0.9961, 1.7021, 1.7021, 0.9961], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 82, Loss 0.431820\n",
      "Params: %f tensor([0.9858, 0.9858, 0.9917, 0.4858, 0.0858, 0.4917], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7015, 1.7015, 0.9957, 1.7015, 1.7015, 0.9957], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 83, Loss 0.431543\n",
      "Params: %f tensor([0.9857, 0.9857, 0.9916, 0.4857, 0.0857, 0.4916], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7009, 1.7009, 0.9953, 1.7009, 1.7009, 0.9953], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 84, Loss 0.431267\n",
      "Params: %f tensor([0.9855, 0.9855, 0.9915, 0.4855, 0.0855, 0.4915], dtype=torch.float64)\n",
      "Grad: %f tensor([1.7002, 1.7002, 0.9949, 1.7002, 1.7002, 0.9949], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 85, Loss 0.430990\n",
      "Params: %f tensor([0.9853, 0.9853, 0.9914, 0.4853, 0.0853, 0.4914], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6996, 1.6996, 0.9945, 1.6996, 1.6996, 0.9945], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 86, Loss 0.430714\n",
      "Params: %f tensor([0.9852, 0.9852, 0.9913, 0.4852, 0.0852, 0.4913], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6990, 1.6990, 0.9941, 1.6990, 1.6990, 0.9941], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 87, Loss 0.430438\n",
      "Params: %f tensor([0.9850, 0.9850, 0.9912, 0.4850, 0.0850, 0.4912], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6984, 1.6984, 0.9937, 1.6984, 1.6984, 0.9937], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 88, Loss 0.430163\n",
      "Params: %f tensor([0.9848, 0.9848, 0.9911, 0.4848, 0.0848, 0.4911], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6978, 1.6978, 0.9933, 1.6978, 1.6978, 0.9933], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 89, Loss 0.429887\n",
      "Params: %f tensor([0.9847, 0.9847, 0.9910, 0.4847, 0.0847, 0.4910], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6972, 1.6972, 0.9929, 1.6972, 1.6972, 0.9929], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 90, Loss 0.429612\n",
      "Params: %f tensor([0.9845, 0.9845, 0.9909, 0.4845, 0.0845, 0.4909], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6966, 1.6966, 0.9925, 1.6966, 1.6966, 0.9925], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 91, Loss 0.429337\n",
      "Params: %f tensor([0.9843, 0.9843, 0.9908, 0.4843, 0.0843, 0.4908], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6959, 1.6959, 0.9921, 1.6959, 1.6959, 0.9921], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 92, Loss 0.429062\n",
      "Params: %f tensor([0.9841, 0.9841, 0.9907, 0.4841, 0.0841, 0.4907], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6953, 1.6953, 0.9917, 1.6953, 1.6953, 0.9917], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 93, Loss 0.428787\n",
      "Params: %f tensor([0.9840, 0.9840, 0.9906, 0.4840, 0.0840, 0.4906], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6947, 1.6947, 0.9913, 1.6947, 1.6947, 0.9913], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 94, Loss 0.428513\n",
      "Params: %f tensor([0.9838, 0.9838, 0.9905, 0.4838, 0.0838, 0.4905], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6941, 1.6941, 0.9909, 1.6941, 1.6941, 0.9909], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 95, Loss 0.428238\n",
      "Params: %f tensor([0.9836, 0.9836, 0.9904, 0.4836, 0.0836, 0.4904], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6935, 1.6935, 0.9905, 1.6935, 1.6935, 0.9905], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 96, Loss 0.427964\n",
      "Params: %f tensor([0.9835, 0.9835, 0.9903, 0.4835, 0.0835, 0.4903], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6929, 1.6929, 0.9901, 1.6929, 1.6929, 0.9901], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 97, Loss 0.427690\n",
      "Params: %f tensor([0.9833, 0.9833, 0.9902, 0.4833, 0.0833, 0.4902], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6923, 1.6923, 0.9897, 1.6923, 1.6923, 0.9897], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 98, Loss 0.427417\n",
      "Params: %f tensor([0.9831, 0.9831, 0.9901, 0.4831, 0.0831, 0.4901], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6917, 1.6917, 0.9893, 1.6917, 1.6917, 0.9893], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 99, Loss 0.427143\n",
      "Params: %f tensor([0.9830, 0.9830, 0.9900, 0.4830, 0.0830, 0.4900], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6910, 1.6910, 0.9889, 1.6910, 1.6910, 0.9889], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 100, Loss 0.426870\n",
      "Params: %f tensor([0.9828, 0.9828, 0.9899, 0.4828, 0.0828, 0.4899], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6904, 1.6904, 0.9885, 1.6904, 1.6904, 0.9885], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 101, Loss 0.426597\n",
      "Params: %f tensor([0.9826, 0.9826, 0.9898, 0.4826, 0.0826, 0.4898], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6898, 1.6898, 0.9881, 1.6898, 1.6898, 0.9881], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 102, Loss 0.426324\n",
      "Params: %f tensor([0.9825, 0.9825, 0.9897, 0.4825, 0.0825, 0.4897], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6892, 1.6892, 0.9877, 1.6892, 1.6892, 0.9877], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 103, Loss 0.426051\n",
      "Params: %f tensor([0.9823, 0.9823, 0.9896, 0.4823, 0.0823, 0.4896], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6886, 1.6886, 0.9873, 1.6886, 1.6886, 0.9873], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 104, Loss 0.425778\n",
      "Params: %f tensor([0.9821, 0.9821, 0.9895, 0.4821, 0.0821, 0.4895], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6880, 1.6880, 0.9869, 1.6880, 1.6880, 0.9869], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 105, Loss 0.425506\n",
      "Params: %f tensor([0.9819, 0.9819, 0.9894, 0.4819, 0.0819, 0.4894], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6874, 1.6874, 0.9865, 1.6874, 1.6874, 0.9865], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 106, Loss 0.425234\n",
      "Params: %f tensor([0.9818, 0.9818, 0.9893, 0.4818, 0.0818, 0.4893], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6868, 1.6868, 0.9861, 1.6868, 1.6868, 0.9861], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 107, Loss 0.424962\n",
      "Params: %f tensor([0.9816, 0.9816, 0.9892, 0.4816, 0.0816, 0.4892], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6861, 1.6861, 0.9857, 1.6861, 1.6861, 0.9857], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 108, Loss 0.424690\n",
      "Params: %f tensor([0.9814, 0.9814, 0.9891, 0.4814, 0.0814, 0.4891], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6855, 1.6855, 0.9853, 1.6855, 1.6855, 0.9853], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 109, Loss 0.424419\n",
      "Params: %f tensor([0.9813, 0.9813, 0.9890, 0.4813, 0.0813, 0.4890], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6849, 1.6849, 0.9849, 1.6849, 1.6849, 0.9849], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 110, Loss 0.424147\n",
      "Params: %f tensor([0.9811, 0.9811, 0.9889, 0.4811, 0.0811, 0.4889], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6843, 1.6843, 0.9845, 1.6843, 1.6843, 0.9845], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 111, Loss 0.423876\n",
      "Params: %f tensor([0.9809, 0.9809, 0.9888, 0.4809, 0.0809, 0.4888], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6837, 1.6837, 0.9841, 1.6837, 1.6837, 0.9841], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 112, Loss 0.423605\n",
      "Params: %f tensor([0.9808, 0.9808, 0.9887, 0.4808, 0.0808, 0.4887], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6831, 1.6831, 0.9837, 1.6831, 1.6831, 0.9837], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 113, Loss 0.423335\n",
      "Params: %f tensor([0.9806, 0.9806, 0.9886, 0.4806, 0.0806, 0.4886], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6825, 1.6825, 0.9833, 1.6825, 1.6825, 0.9833], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 114, Loss 0.423064\n",
      "Params: %f tensor([0.9804, 0.9804, 0.9885, 0.4804, 0.0804, 0.4885], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6819, 1.6819, 0.9829, 1.6819, 1.6819, 0.9829], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 115, Loss 0.422794\n",
      "Params: %f tensor([0.9803, 0.9803, 0.9884, 0.4803, 0.0803, 0.4884], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6813, 1.6813, 0.9825, 1.6813, 1.6813, 0.9825], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 116, Loss 0.422524\n",
      "Params: %f tensor([0.9801, 0.9801, 0.9883, 0.4801, 0.0801, 0.4883], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6807, 1.6807, 0.9822, 1.6807, 1.6807, 0.9822], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 117, Loss 0.422254\n",
      "Params: %f tensor([0.9799, 0.9799, 0.9882, 0.4799, 0.0799, 0.4882], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6801, 1.6801, 0.9818, 1.6801, 1.6801, 0.9818], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 118, Loss 0.421984\n",
      "Params: %f tensor([0.9798, 0.9798, 0.9881, 0.4798, 0.0798, 0.4881], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6794, 1.6794, 0.9814, 1.6794, 1.6794, 0.9814], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 119, Loss 0.421714\n",
      "Params: %f tensor([0.9796, 0.9796, 0.9880, 0.4796, 0.0796, 0.4880], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6788, 1.6788, 0.9810, 1.6788, 1.6788, 0.9810], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 120, Loss 0.421445\n",
      "Params: %f tensor([0.9794, 0.9794, 0.9879, 0.4794, 0.0794, 0.4879], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6782, 1.6782, 0.9806, 1.6782, 1.6782, 0.9806], dtype=torch.float64)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121, Loss 0.421176\n",
      "Params: %f tensor([0.9793, 0.9793, 0.9878, 0.4793, 0.0793, 0.4878], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6776, 1.6776, 0.9802, 1.6776, 1.6776, 0.9802], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 122, Loss 0.420907\n",
      "Params: %f tensor([0.9791, 0.9791, 0.9878, 0.4791, 0.0791, 0.4878], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6770, 1.6770, 0.9798, 1.6770, 1.6770, 0.9798], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 123, Loss 0.420638\n",
      "Params: %f tensor([0.9789, 0.9789, 0.9877, 0.4789, 0.0789, 0.4877], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6764, 1.6764, 0.9794, 1.6764, 1.6764, 0.9794], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 124, Loss 0.420369\n",
      "Params: %f tensor([0.9788, 0.9788, 0.9876, 0.4788, 0.0788, 0.4876], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6758, 1.6758, 0.9790, 1.6758, 1.6758, 0.9790], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 125, Loss 0.420101\n",
      "Params: %f tensor([0.9786, 0.9786, 0.9875, 0.4786, 0.0786, 0.4875], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6752, 1.6752, 0.9786, 1.6752, 1.6752, 0.9786], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 126, Loss 0.419833\n",
      "Params: %f tensor([0.9784, 0.9784, 0.9874, 0.4784, 0.0784, 0.4874], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6746, 1.6746, 0.9782, 1.6746, 1.6746, 0.9782], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 127, Loss 0.419565\n",
      "Params: %f tensor([0.9782, 0.9782, 0.9873, 0.4782, 0.0782, 0.4873], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6740, 1.6740, 0.9778, 1.6740, 1.6740, 0.9778], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 128, Loss 0.419297\n",
      "Params: %f tensor([0.9781, 0.9781, 0.9872, 0.4781, 0.0781, 0.4872], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6734, 1.6734, 0.9774, 1.6734, 1.6734, 0.9774], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 129, Loss 0.419029\n",
      "Params: %f tensor([0.9779, 0.9779, 0.9871, 0.4779, 0.0779, 0.4871], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6728, 1.6728, 0.9770, 1.6728, 1.6728, 0.9770], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 130, Loss 0.418762\n",
      "Params: %f tensor([0.9777, 0.9777, 0.9870, 0.4777, 0.0777, 0.4870], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6722, 1.6722, 0.9766, 1.6722, 1.6722, 0.9766], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 131, Loss 0.418495\n",
      "Params: %f tensor([0.9776, 0.9776, 0.9869, 0.4776, 0.0776, 0.4869], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6716, 1.6716, 0.9762, 1.6716, 1.6716, 0.9762], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 132, Loss 0.418228\n",
      "Params: %f tensor([0.9774, 0.9774, 0.9868, 0.4774, 0.0774, 0.4868], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6710, 1.6710, 0.9758, 1.6710, 1.6710, 0.9758], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 133, Loss 0.417961\n",
      "Params: %f tensor([0.9772, 0.9772, 0.9867, 0.4772, 0.0772, 0.4867], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6703, 1.6703, 0.9755, 1.6703, 1.6703, 0.9755], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 134, Loss 0.417694\n",
      "Params: %f tensor([0.9771, 0.9771, 0.9866, 0.4771, 0.0771, 0.4866], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6697, 1.6697, 0.9751, 1.6697, 1.6697, 0.9751], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 135, Loss 0.417428\n",
      "Params: %f tensor([0.9769, 0.9769, 0.9865, 0.4769, 0.0769, 0.4865], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6691, 1.6691, 0.9747, 1.6691, 1.6691, 0.9747], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 136, Loss 0.417162\n",
      "Params: %f tensor([0.9767, 0.9767, 0.9864, 0.4767, 0.0767, 0.4864], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6685, 1.6685, 0.9743, 1.6685, 1.6685, 0.9743], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 137, Loss 0.416896\n",
      "Params: %f tensor([0.9766, 0.9766, 0.9863, 0.4766, 0.0766, 0.4863], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6679, 1.6679, 0.9739, 1.6679, 1.6679, 0.9739], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 138, Loss 0.416630\n",
      "Params: %f tensor([0.9764, 0.9764, 0.9862, 0.4764, 0.0764, 0.4862], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6673, 1.6673, 0.9735, 1.6673, 1.6673, 0.9735], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 139, Loss 0.416364\n",
      "Params: %f tensor([0.9762, 0.9762, 0.9861, 0.4762, 0.0762, 0.4861], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6667, 1.6667, 0.9731, 1.6667, 1.6667, 0.9731], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 140, Loss 0.416099\n",
      "Params: %f tensor([0.9761, 0.9761, 0.9860, 0.4761, 0.0761, 0.4860], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6661, 1.6661, 0.9727, 1.6661, 1.6661, 0.9727], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 141, Loss 0.415833\n",
      "Params: %f tensor([0.9759, 0.9759, 0.9859, 0.4759, 0.0759, 0.4859], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6655, 1.6655, 0.9723, 1.6655, 1.6655, 0.9723], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 142, Loss 0.415568\n",
      "Params: %f tensor([0.9757, 0.9757, 0.9858, 0.4757, 0.0757, 0.4858], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6649, 1.6649, 0.9719, 1.6649, 1.6649, 0.9719], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 143, Loss 0.415303\n",
      "Params: %f tensor([0.9756, 0.9756, 0.9857, 0.4756, 0.0756, 0.4857], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6643, 1.6643, 0.9715, 1.6643, 1.6643, 0.9715], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 144, Loss 0.415039\n",
      "Params: %f tensor([0.9754, 0.9754, 0.9856, 0.4754, 0.0754, 0.4856], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6637, 1.6637, 0.9711, 1.6637, 1.6637, 0.9711], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 145, Loss 0.414774\n",
      "Params: %f tensor([0.9752, 0.9752, 0.9855, 0.4752, 0.0752, 0.4855], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6631, 1.6631, 0.9707, 1.6631, 1.6631, 0.9707], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 146, Loss 0.414510\n",
      "Params: %f tensor([0.9751, 0.9751, 0.9854, 0.4751, 0.0751, 0.4854], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6625, 1.6625, 0.9704, 1.6625, 1.6625, 0.9704], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 147, Loss 0.414246\n",
      "Params: %f tensor([0.9749, 0.9749, 0.9853, 0.4749, 0.0749, 0.4853], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6619, 1.6619, 0.9700, 1.6619, 1.6619, 0.9700], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 148, Loss 0.413982\n",
      "Params: %f tensor([0.9747, 0.9747, 0.9852, 0.4747, 0.0747, 0.4852], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6613, 1.6613, 0.9696, 1.6613, 1.6613, 0.9696], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 149, Loss 0.413718\n",
      "Params: %f tensor([0.9746, 0.9746, 0.9851, 0.4746, 0.0746, 0.4851], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6607, 1.6607, 0.9692, 1.6607, 1.6607, 0.9692], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 150, Loss 0.413455\n",
      "Params: %f tensor([0.9744, 0.9744, 0.9850, 0.4744, 0.0744, 0.4850], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6601, 1.6601, 0.9688, 1.6601, 1.6601, 0.9688], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 151, Loss 0.413191\n",
      "Params: %f tensor([0.9742, 0.9742, 0.9849, 0.4742, 0.0742, 0.4849], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6595, 1.6595, 0.9684, 1.6595, 1.6595, 0.9684], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 152, Loss 0.412928\n",
      "Params: %f tensor([0.9741, 0.9741, 0.9848, 0.4741, 0.0741, 0.4848], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6589, 1.6589, 0.9680, 1.6589, 1.6589, 0.9680], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 153, Loss 0.412665\n",
      "Params: %f tensor([0.9739, 0.9739, 0.9847, 0.4739, 0.0739, 0.4847], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6583, 1.6583, 0.9676, 1.6583, 1.6583, 0.9676], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 154, Loss 0.412402\n",
      "Params: %f tensor([0.9738, 0.9738, 0.9846, 0.4738, 0.0738, 0.4846], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6577, 1.6577, 0.9672, 1.6577, 1.6577, 0.9672], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 155, Loss 0.412140\n",
      "Params: %f tensor([0.9736, 0.9736, 0.9845, 0.4736, 0.0736, 0.4845], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6571, 1.6571, 0.9668, 1.6571, 1.6571, 0.9668], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 156, Loss 0.411877\n",
      "Params: %f tensor([0.9734, 0.9734, 0.9844, 0.4734, 0.0734, 0.4844], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6565, 1.6565, 0.9664, 1.6565, 1.6565, 0.9664], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 157, Loss 0.411615\n",
      "Params: %f tensor([0.9733, 0.9733, 0.9843, 0.4733, 0.0733, 0.4843], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6559, 1.6559, 0.9661, 1.6559, 1.6559, 0.9661], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 158, Loss 0.411353\n",
      "Params: %f tensor([0.9731, 0.9731, 0.9842, 0.4731, 0.0731, 0.4842], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6553, 1.6553, 0.9657, 1.6553, 1.6553, 0.9657], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 159, Loss 0.411091\n",
      "Params: %f tensor([0.9729, 0.9729, 0.9842, 0.4729, 0.0729, 0.4842], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6547, 1.6547, 0.9653, 1.6547, 1.6547, 0.9653], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 160, Loss 0.410830\n",
      "Params: %f tensor([0.9728, 0.9728, 0.9841, 0.4728, 0.0728, 0.4841], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6541, 1.6541, 0.9649, 1.6541, 1.6541, 0.9649], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 161, Loss 0.410568\n",
      "Params: %f tensor([0.9726, 0.9726, 0.9840, 0.4726, 0.0726, 0.4840], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6535, 1.6535, 0.9645, 1.6535, 1.6535, 0.9645], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 162, Loss 0.410307\n",
      "Params: %f tensor([0.9724, 0.9724, 0.9839, 0.4724, 0.0724, 0.4839], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6529, 1.6529, 0.9641, 1.6529, 1.6529, 0.9641], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 163, Loss 0.410046\n",
      "Params: %f tensor([0.9723, 0.9723, 0.9838, 0.4723, 0.0723, 0.4838], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6523, 1.6523, 0.9637, 1.6523, 1.6523, 0.9637], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 164, Loss 0.409785\n",
      "Params: %f tensor([0.9721, 0.9721, 0.9837, 0.4721, 0.0721, 0.4837], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6517, 1.6517, 0.9633, 1.6517, 1.6517, 0.9633], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 165, Loss 0.409524\n",
      "Params: %f tensor([0.9719, 0.9719, 0.9836, 0.4719, 0.0719, 0.4836], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6511, 1.6511, 0.9629, 1.6511, 1.6511, 0.9629], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 166, Loss 0.409264\n",
      "Params: %f tensor([0.9718, 0.9718, 0.9835, 0.4718, 0.0718, 0.4835], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6505, 1.6505, 0.9626, 1.6505, 1.6505, 0.9626], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 167, Loss 0.409004\n",
      "Params: %f tensor([0.9716, 0.9716, 0.9834, 0.4716, 0.0716, 0.4834], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6499, 1.6499, 0.9622, 1.6499, 1.6499, 0.9622], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 168, Loss 0.408744\n",
      "Params: %f tensor([0.9714, 0.9714, 0.9833, 0.4714, 0.0714, 0.4833], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6493, 1.6493, 0.9618, 1.6493, 1.6493, 0.9618], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 169, Loss 0.408484\n",
      "Params: %f tensor([0.9713, 0.9713, 0.9832, 0.4713, 0.0713, 0.4832], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6487, 1.6487, 0.9614, 1.6487, 1.6487, 0.9614], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 170, Loss 0.408224\n",
      "Params: %f tensor([0.9711, 0.9711, 0.9831, 0.4711, 0.0711, 0.4831], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6481, 1.6481, 0.9610, 1.6481, 1.6481, 0.9610], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 171, Loss 0.407964\n",
      "Params: %f tensor([0.9709, 0.9709, 0.9830, 0.4709, 0.0709, 0.4830], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6475, 1.6475, 0.9606, 1.6475, 1.6475, 0.9606], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 172, Loss 0.407705\n",
      "Params: %f tensor([0.9708, 0.9708, 0.9829, 0.4708, 0.0708, 0.4829], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6469, 1.6469, 0.9602, 1.6469, 1.6469, 0.9602], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 173, Loss 0.407446\n",
      "Params: %f tensor([0.9706, 0.9706, 0.9828, 0.4706, 0.0706, 0.4828], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6463, 1.6463, 0.9598, 1.6463, 1.6463, 0.9598], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 174, Loss 0.407187\n",
      "Params: %f tensor([0.9704, 0.9704, 0.9827, 0.4704, 0.0704, 0.4827], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6457, 1.6457, 0.9595, 1.6457, 1.6457, 0.9595], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 175, Loss 0.406928\n",
      "Params: %f tensor([0.9703, 0.9703, 0.9826, 0.4703, 0.0703, 0.4826], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6451, 1.6451, 0.9591, 1.6451, 1.6451, 0.9591], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 176, Loss 0.406670\n",
      "Params: %f tensor([0.9701, 0.9701, 0.9825, 0.4701, 0.0701, 0.4825], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6445, 1.6445, 0.9587, 1.6445, 1.6445, 0.9587], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 177, Loss 0.406411\n",
      "Params: %f tensor([0.9700, 0.9700, 0.9824, 0.4700, 0.0700, 0.4824], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6439, 1.6439, 0.9583, 1.6439, 1.6439, 0.9583], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 178, Loss 0.406153\n",
      "Params: %f tensor([0.9698, 0.9698, 0.9823, 0.4698, 0.0698, 0.4823], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6434, 1.6434, 0.9579, 1.6434, 1.6434, 0.9579], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 179, Loss 0.405895\n",
      "Params: %f tensor([0.9696, 0.9696, 0.9822, 0.4696, 0.0696, 0.4822], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6428, 1.6428, 0.9575, 1.6428, 1.6428, 0.9575], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 180, Loss 0.405637\n",
      "Params: %f tensor([0.9695, 0.9695, 0.9821, 0.4695, 0.0695, 0.4821], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6422, 1.6422, 0.9571, 1.6422, 1.6422, 0.9571], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 181, Loss 0.405379\n",
      "Params: %f tensor([0.9693, 0.9693, 0.9820, 0.4693, 0.0693, 0.4820], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6416, 1.6416, 0.9567, 1.6416, 1.6416, 0.9567], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 182, Loss 0.405122\n",
      "Params: %f tensor([0.9691, 0.9691, 0.9819, 0.4691, 0.0691, 0.4819], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6410, 1.6410, 0.9564, 1.6410, 1.6410, 0.9564], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 183, Loss 0.404865\n",
      "Params: %f tensor([0.9690, 0.9690, 0.9818, 0.4690, 0.0690, 0.4818], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6404, 1.6404, 0.9560, 1.6404, 1.6404, 0.9560], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 184, Loss 0.404608\n",
      "Params: %f tensor([0.9688, 0.9688, 0.9818, 0.4688, 0.0688, 0.4818], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6398, 1.6398, 0.9556, 1.6398, 1.6398, 0.9556], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 185, Loss 0.404351\n",
      "Params: %f tensor([0.9686, 0.9686, 0.9817, 0.4686, 0.0686, 0.4817], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6392, 1.6392, 0.9552, 1.6392, 1.6392, 0.9552], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 186, Loss 0.404094\n",
      "Params: %f tensor([0.9685, 0.9685, 0.9816, 0.4685, 0.0685, 0.4816], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6386, 1.6386, 0.9548, 1.6386, 1.6386, 0.9548], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 187, Loss 0.403837\n",
      "Params: %f tensor([0.9683, 0.9683, 0.9815, 0.4683, 0.0683, 0.4815], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6380, 1.6380, 0.9544, 1.6380, 1.6380, 0.9544], dtype=torch.float64)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188, Loss 0.403581\n",
      "Params: %f tensor([0.9682, 0.9682, 0.9814, 0.4682, 0.0682, 0.4814], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6374, 1.6374, 0.9540, 1.6374, 1.6374, 0.9540], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 189, Loss 0.403325\n",
      "Params: %f tensor([0.9680, 0.9680, 0.9813, 0.4680, 0.0680, 0.4813], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6368, 1.6368, 0.9537, 1.6368, 1.6368, 0.9537], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 190, Loss 0.403069\n",
      "Params: %f tensor([0.9678, 0.9678, 0.9812, 0.4678, 0.0678, 0.4812], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6362, 1.6362, 0.9533, 1.6362, 1.6362, 0.9533], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 191, Loss 0.402813\n",
      "Params: %f tensor([0.9677, 0.9677, 0.9811, 0.4677, 0.0677, 0.4811], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6356, 1.6356, 0.9529, 1.6356, 1.6356, 0.9529], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 192, Loss 0.402558\n",
      "Params: %f tensor([0.9675, 0.9675, 0.9810, 0.4675, 0.0675, 0.4810], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6350, 1.6350, 0.9525, 1.6350, 1.6350, 0.9525], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 193, Loss 0.402302\n",
      "Params: %f tensor([0.9673, 0.9673, 0.9809, 0.4673, 0.0673, 0.4809], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6345, 1.6345, 0.9521, 1.6345, 1.6345, 0.9521], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 194, Loss 0.402047\n",
      "Params: %f tensor([0.9672, 0.9672, 0.9808, 0.4672, 0.0672, 0.4808], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6339, 1.6339, 0.9517, 1.6339, 1.6339, 0.9517], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 195, Loss 0.401792\n",
      "Params: %f tensor([0.9670, 0.9670, 0.9807, 0.4670, 0.0670, 0.4807], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6333, 1.6333, 0.9514, 1.6333, 1.6333, 0.9514], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 196, Loss 0.401537\n",
      "Params: %f tensor([0.9668, 0.9668, 0.9806, 0.4668, 0.0668, 0.4806], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6327, 1.6327, 0.9510, 1.6327, 1.6327, 0.9510], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 197, Loss 0.401282\n",
      "Params: %f tensor([0.9667, 0.9667, 0.9805, 0.4667, 0.0667, 0.4805], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6321, 1.6321, 0.9506, 1.6321, 1.6321, 0.9506], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 198, Loss 0.401028\n",
      "Params: %f tensor([0.9665, 0.9665, 0.9804, 0.4665, 0.0665, 0.4804], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6315, 1.6315, 0.9502, 1.6315, 1.6315, 0.9502], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 199, Loss 0.400774\n",
      "Params: %f tensor([0.9664, 0.9664, 0.9803, 0.4664, 0.0664, 0.4803], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6309, 1.6309, 0.9498, 1.6309, 1.6309, 0.9498], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 200, Loss 0.400519\n",
      "Params: %f tensor([0.9662, 0.9662, 0.9802, 0.4662, 0.0662, 0.4802], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6303, 1.6303, 0.9494, 1.6303, 1.6303, 0.9494], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 201, Loss 0.400266\n",
      "Params: %f tensor([0.9660, 0.9660, 0.9801, 0.4660, 0.0660, 0.4801], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6297, 1.6297, 0.9491, 1.6297, 1.6297, 0.9491], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 202, Loss 0.400012\n",
      "Params: %f tensor([0.9659, 0.9659, 0.9800, 0.4659, 0.0659, 0.4800], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6291, 1.6291, 0.9487, 1.6291, 1.6291, 0.9487], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 203, Loss 0.399758\n",
      "Params: %f tensor([0.9657, 0.9657, 0.9799, 0.4657, 0.0657, 0.4799], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6285, 1.6285, 0.9483, 1.6285, 1.6285, 0.9483], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 204, Loss 0.399505\n",
      "Params: %f tensor([0.9655, 0.9655, 0.9798, 0.4655, 0.0655, 0.4798], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6280, 1.6280, 0.9479, 1.6280, 1.6280, 0.9479], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 205, Loss 0.399252\n",
      "Params: %f tensor([0.9654, 0.9654, 0.9798, 0.4654, 0.0654, 0.4798], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6274, 1.6274, 0.9475, 1.6274, 1.6274, 0.9475], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 206, Loss 0.398999\n",
      "Params: %f tensor([0.9652, 0.9652, 0.9797, 0.4652, 0.0652, 0.4797], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6268, 1.6268, 0.9471, 1.6268, 1.6268, 0.9471], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 207, Loss 0.398746\n",
      "Params: %f tensor([0.9651, 0.9651, 0.9796, 0.4651, 0.0651, 0.4796], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6262, 1.6262, 0.9468, 1.6262, 1.6262, 0.9468], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 208, Loss 0.398493\n",
      "Params: %f tensor([0.9649, 0.9649, 0.9795, 0.4649, 0.0649, 0.4795], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6256, 1.6256, 0.9464, 1.6256, 1.6256, 0.9464], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 209, Loss 0.398241\n",
      "Params: %f tensor([0.9647, 0.9647, 0.9794, 0.4647, 0.0647, 0.4794], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6250, 1.6250, 0.9460, 1.6250, 1.6250, 0.9460], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 210, Loss 0.397989\n",
      "Params: %f tensor([0.9646, 0.9646, 0.9793, 0.4646, 0.0646, 0.4793], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6244, 1.6244, 0.9456, 1.6244, 1.6244, 0.9456], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 211, Loss 0.397736\n",
      "Params: %f tensor([0.9644, 0.9644, 0.9792, 0.4644, 0.0644, 0.4792], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6238, 1.6238, 0.9452, 1.6238, 1.6238, 0.9452], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 212, Loss 0.397485\n",
      "Params: %f tensor([0.9642, 0.9642, 0.9791, 0.4642, 0.0642, 0.4791], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6232, 1.6232, 0.9448, 1.6232, 1.6232, 0.9448], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 213, Loss 0.397233\n",
      "Params: %f tensor([0.9641, 0.9641, 0.9790, 0.4641, 0.0641, 0.4790], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6227, 1.6227, 0.9445, 1.6227, 1.6227, 0.9445], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 214, Loss 0.396981\n",
      "Params: %f tensor([0.9639, 0.9639, 0.9789, 0.4639, 0.0639, 0.4789], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6221, 1.6221, 0.9441, 1.6221, 1.6221, 0.9441], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 215, Loss 0.396730\n",
      "Params: %f tensor([0.9638, 0.9638, 0.9788, 0.4638, 0.0638, 0.4788], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6215, 1.6215, 0.9437, 1.6215, 1.6215, 0.9437], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 216, Loss 0.396479\n",
      "Params: %f tensor([0.9636, 0.9636, 0.9787, 0.4636, 0.0636, 0.4787], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6209, 1.6209, 0.9433, 1.6209, 1.6209, 0.9433], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 217, Loss 0.396228\n",
      "Params: %f tensor([0.9634, 0.9634, 0.9786, 0.4634, 0.0634, 0.4786], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6203, 1.6203, 0.9429, 1.6203, 1.6203, 0.9429], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 218, Loss 0.395977\n",
      "Params: %f tensor([0.9633, 0.9633, 0.9785, 0.4633, 0.0633, 0.4785], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6197, 1.6197, 0.9426, 1.6197, 1.6197, 0.9426], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 219, Loss 0.395726\n",
      "Params: %f tensor([0.9631, 0.9631, 0.9784, 0.4631, 0.0631, 0.4784], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6191, 1.6191, 0.9422, 1.6191, 1.6191, 0.9422], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 220, Loss 0.395476\n",
      "Params: %f tensor([0.9629, 0.9629, 0.9783, 0.4629, 0.0629, 0.4783], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6186, 1.6186, 0.9418, 1.6186, 1.6186, 0.9418], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 221, Loss 0.395226\n",
      "Params: %f tensor([0.9628, 0.9628, 0.9782, 0.4628, 0.0628, 0.4782], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6180, 1.6180, 0.9414, 1.6180, 1.6180, 0.9414], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 222, Loss 0.394976\n",
      "Params: %f tensor([0.9626, 0.9626, 0.9782, 0.4626, 0.0626, 0.4782], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6174, 1.6174, 0.9410, 1.6174, 1.6174, 0.9410], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 223, Loss 0.394726\n",
      "Params: %f tensor([0.9625, 0.9625, 0.9781, 0.4625, 0.0625, 0.4781], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6168, 1.6168, 0.9407, 1.6168, 1.6168, 0.9407], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 224, Loss 0.394476\n",
      "Params: %f tensor([0.9623, 0.9623, 0.9780, 0.4623, 0.0623, 0.4780], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6162, 1.6162, 0.9403, 1.6162, 1.6162, 0.9403], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 225, Loss 0.394227\n",
      "Params: %f tensor([0.9621, 0.9621, 0.9779, 0.4621, 0.0621, 0.4779], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6156, 1.6156, 0.9399, 1.6156, 1.6156, 0.9399], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 226, Loss 0.393977\n",
      "Params: %f tensor([0.9620, 0.9620, 0.9778, 0.4620, 0.0620, 0.4778], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6150, 1.6150, 0.9395, 1.6150, 1.6150, 0.9395], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 227, Loss 0.393728\n",
      "Params: %f tensor([0.9618, 0.9618, 0.9777, 0.4618, 0.0618, 0.4777], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6145, 1.6145, 0.9391, 1.6145, 1.6145, 0.9391], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 228, Loss 0.393479\n",
      "Params: %f tensor([0.9616, 0.9616, 0.9776, 0.4616, 0.0616, 0.4776], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6139, 1.6139, 0.9388, 1.6139, 1.6139, 0.9388], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 229, Loss 0.393230\n",
      "Params: %f tensor([0.9615, 0.9615, 0.9775, 0.4615, 0.0615, 0.4775], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6133, 1.6133, 0.9384, 1.6133, 1.6133, 0.9384], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 230, Loss 0.392982\n",
      "Params: %f tensor([0.9613, 0.9613, 0.9774, 0.4613, 0.0613, 0.4774], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6127, 1.6127, 0.9380, 1.6127, 1.6127, 0.9380], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 231, Loss 0.392733\n",
      "Params: %f tensor([0.9612, 0.9612, 0.9773, 0.4612, 0.0612, 0.4773], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6121, 1.6121, 0.9376, 1.6121, 1.6121, 0.9376], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 232, Loss 0.392485\n",
      "Params: %f tensor([0.9610, 0.9610, 0.9772, 0.4610, 0.0610, 0.4772], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6115, 1.6115, 0.9372, 1.6115, 1.6115, 0.9372], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 233, Loss 0.392237\n",
      "Params: %f tensor([0.9608, 0.9608, 0.9771, 0.4608, 0.0608, 0.4771], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6110, 1.6110, 0.9369, 1.6110, 1.6110, 0.9369], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 234, Loss 0.391989\n",
      "Params: %f tensor([0.9607, 0.9607, 0.9770, 0.4607, 0.0607, 0.4770], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6104, 1.6104, 0.9365, 1.6104, 1.6104, 0.9365], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 235, Loss 0.391741\n",
      "Params: %f tensor([0.9605, 0.9605, 0.9769, 0.4605, 0.0605, 0.4769], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6098, 1.6098, 0.9361, 1.6098, 1.6098, 0.9361], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 236, Loss 0.391494\n",
      "Params: %f tensor([0.9604, 0.9604, 0.9768, 0.4604, 0.0604, 0.4768], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6092, 1.6092, 0.9357, 1.6092, 1.6092, 0.9357], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 237, Loss 0.391246\n",
      "Params: %f tensor([0.9602, 0.9602, 0.9767, 0.4602, 0.0602, 0.4767], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6086, 1.6086, 0.9353, 1.6086, 1.6086, 0.9353], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 238, Loss 0.390999\n",
      "Params: %f tensor([0.9600, 0.9600, 0.9766, 0.4600, 0.0600, 0.4766], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6080, 1.6080, 0.9350, 1.6080, 1.6080, 0.9350], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 239, Loss 0.390752\n",
      "Params: %f tensor([0.9599, 0.9599, 0.9766, 0.4599, 0.0599, 0.4766], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6075, 1.6075, 0.9346, 1.6075, 1.6075, 0.9346], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 240, Loss 0.390505\n",
      "Params: %f tensor([0.9597, 0.9597, 0.9765, 0.4597, 0.0597, 0.4765], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6069, 1.6069, 0.9342, 1.6069, 1.6069, 0.9342], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 241, Loss 0.390259\n",
      "Params: %f tensor([0.9596, 0.9596, 0.9764, 0.4596, 0.0596, 0.4764], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6063, 1.6063, 0.9338, 1.6063, 1.6063, 0.9338], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 242, Loss 0.390012\n",
      "Params: %f tensor([0.9594, 0.9594, 0.9763, 0.4594, 0.0594, 0.4763], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6057, 1.6057, 0.9334, 1.6057, 1.6057, 0.9334], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 243, Loss 0.389766\n",
      "Params: %f tensor([0.9592, 0.9592, 0.9762, 0.4592, 0.0592, 0.4762], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6051, 1.6051, 0.9331, 1.6051, 1.6051, 0.9331], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 244, Loss 0.389520\n",
      "Params: %f tensor([0.9591, 0.9591, 0.9761, 0.4591, 0.0591, 0.4761], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6046, 1.6046, 0.9327, 1.6046, 1.6046, 0.9327], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 245, Loss 0.389274\n",
      "Params: %f tensor([0.9589, 0.9589, 0.9760, 0.4589, 0.0589, 0.4760], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6040, 1.6040, 0.9323, 1.6040, 1.6040, 0.9323], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 246, Loss 0.389028\n",
      "Params: %f tensor([0.9588, 0.9588, 0.9759, 0.4588, 0.0588, 0.4759], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6034, 1.6034, 0.9319, 1.6034, 1.6034, 0.9319], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 247, Loss 0.388783\n",
      "Params: %f tensor([0.9586, 0.9586, 0.9758, 0.4586, 0.0586, 0.4758], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6028, 1.6028, 0.9316, 1.6028, 1.6028, 0.9316], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 248, Loss 0.388537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: %f tensor([0.9584, 0.9584, 0.9757, 0.4584, 0.0584, 0.4757], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6022, 1.6022, 0.9312, 1.6022, 1.6022, 0.9312], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 249, Loss 0.388292\n",
      "Params: %f tensor([0.9583, 0.9583, 0.9756, 0.4583, 0.0583, 0.4756], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6017, 1.6017, 0.9308, 1.6017, 1.6017, 0.9308], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 250, Loss 0.388047\n",
      "Params: %f tensor([0.9581, 0.9581, 0.9755, 0.4581, 0.0581, 0.4755], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6011, 1.6011, 0.9304, 1.6011, 1.6011, 0.9304], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 251, Loss 0.387802\n",
      "Params: %f tensor([0.9580, 0.9580, 0.9754, 0.4580, 0.0580, 0.4754], dtype=torch.float64)\n",
      "Grad: %f tensor([1.6005, 1.6005, 0.9301, 1.6005, 1.6005, 0.9301], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 252, Loss 0.387558\n",
      "Params: %f tensor([0.9578, 0.9578, 0.9753, 0.4578, 0.0578, 0.4753], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5999, 1.5999, 0.9297, 1.5999, 1.5999, 0.9297], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 253, Loss 0.387313\n",
      "Params: %f tensor([0.9576, 0.9576, 0.9753, 0.4576, 0.0576, 0.4753], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5993, 1.5993, 0.9293, 1.5993, 1.5993, 0.9293], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 254, Loss 0.387069\n",
      "Params: %f tensor([0.9575, 0.9575, 0.9752, 0.4575, 0.0575, 0.4752], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5988, 1.5988, 0.9289, 1.5988, 1.5988, 0.9289], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 255, Loss 0.386825\n",
      "Params: %f tensor([0.9573, 0.9573, 0.9751, 0.4573, 0.0573, 0.4751], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5982, 1.5982, 0.9286, 1.5982, 1.5982, 0.9286], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 256, Loss 0.386581\n",
      "Params: %f tensor([0.9572, 0.9572, 0.9750, 0.4572, 0.0572, 0.4750], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5976, 1.5976, 0.9282, 1.5976, 1.5976, 0.9282], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 257, Loss 0.386337\n",
      "Params: %f tensor([0.9570, 0.9570, 0.9749, 0.4570, 0.0570, 0.4749], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5970, 1.5970, 0.9278, 1.5970, 1.5970, 0.9278], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 258, Loss 0.386093\n",
      "Params: %f tensor([0.9568, 0.9568, 0.9748, 0.4568, 0.0568, 0.4748], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5964, 1.5964, 0.9274, 1.5964, 1.5964, 0.9274], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 259, Loss 0.385850\n",
      "Params: %f tensor([0.9567, 0.9567, 0.9747, 0.4567, 0.0567, 0.4747], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5959, 1.5959, 0.9270, 1.5959, 1.5959, 0.9270], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 260, Loss 0.385607\n",
      "Params: %f tensor([0.9565, 0.9565, 0.9746, 0.4565, 0.0565, 0.4746], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5953, 1.5953, 0.9267, 1.5953, 1.5953, 0.9267], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 261, Loss 0.385364\n",
      "Params: %f tensor([0.9564, 0.9564, 0.9745, 0.4564, 0.0564, 0.4745], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5947, 1.5947, 0.9263, 1.5947, 1.5947, 0.9263], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 262, Loss 0.385121\n",
      "Params: %f tensor([0.9562, 0.9562, 0.9744, 0.4562, 0.0562, 0.4744], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5941, 1.5941, 0.9259, 1.5941, 1.5941, 0.9259], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 263, Loss 0.384878\n",
      "Params: %f tensor([0.9560, 0.9560, 0.9743, 0.4560, 0.0560, 0.4743], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5936, 1.5936, 0.9255, 1.5936, 1.5936, 0.9255], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 264, Loss 0.384636\n",
      "Params: %f tensor([0.9559, 0.9559, 0.9742, 0.4559, 0.0559, 0.4742], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5930, 1.5930, 0.9252, 1.5930, 1.5930, 0.9252], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 265, Loss 0.384393\n",
      "Params: %f tensor([0.9557, 0.9557, 0.9741, 0.4557, 0.0557, 0.4741], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5924, 1.5924, 0.9248, 1.5924, 1.5924, 0.9248], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 266, Loss 0.384151\n",
      "Params: %f tensor([0.9556, 0.9556, 0.9740, 0.4556, 0.0556, 0.4740], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5918, 1.5918, 0.9244, 1.5918, 1.5918, 0.9244], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 267, Loss 0.383909\n",
      "Params: %f tensor([0.9554, 0.9554, 0.9740, 0.4554, 0.0554, 0.4740], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5913, 1.5913, 0.9240, 1.5913, 1.5913, 0.9240], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 268, Loss 0.383667\n",
      "Params: %f tensor([0.9552, 0.9552, 0.9739, 0.4552, 0.0552, 0.4739], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5907, 1.5907, 0.9237, 1.5907, 1.5907, 0.9237], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 269, Loss 0.383426\n",
      "Params: %f tensor([0.9551, 0.9551, 0.9738, 0.4551, 0.0551, 0.4738], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5901, 1.5901, 0.9233, 1.5901, 1.5901, 0.9233], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 270, Loss 0.383184\n",
      "Params: %f tensor([0.9549, 0.9549, 0.9737, 0.4549, 0.0549, 0.4737], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5895, 1.5895, 0.9229, 1.5895, 1.5895, 0.9229], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 271, Loss 0.382943\n",
      "Params: %f tensor([0.9548, 0.9548, 0.9736, 0.4548, 0.0548, 0.4736], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5889, 1.5889, 0.9226, 1.5889, 1.5889, 0.9226], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 272, Loss 0.382702\n",
      "Params: %f tensor([0.9546, 0.9546, 0.9735, 0.4546, 0.0546, 0.4735], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5884, 1.5884, 0.9222, 1.5884, 1.5884, 0.9222], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 273, Loss 0.382461\n",
      "Params: %f tensor([0.9544, 0.9544, 0.9734, 0.4544, 0.0544, 0.4734], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5878, 1.5878, 0.9218, 1.5878, 1.5878, 0.9218], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 274, Loss 0.382220\n",
      "Params: %f tensor([0.9543, 0.9543, 0.9733, 0.4543, 0.0543, 0.4733], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5872, 1.5872, 0.9214, 1.5872, 1.5872, 0.9214], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 275, Loss 0.381979\n",
      "Params: %f tensor([0.9541, 0.9541, 0.9732, 0.4541, 0.0541, 0.4732], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5867, 1.5867, 0.9211, 1.5867, 1.5867, 0.9211], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 276, Loss 0.381739\n",
      "Params: %f tensor([0.9540, 0.9540, 0.9731, 0.4540, 0.0540, 0.4731], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5861, 1.5861, 0.9207, 1.5861, 1.5861, 0.9207], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 277, Loss 0.381499\n",
      "Params: %f tensor([0.9538, 0.9538, 0.9730, 0.4538, 0.0538, 0.4730], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5855, 1.5855, 0.9203, 1.5855, 1.5855, 0.9203], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 278, Loss 0.381259\n",
      "Params: %f tensor([0.9537, 0.9537, 0.9729, 0.4537, 0.0537, 0.4729], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5849, 1.5849, 0.9199, 1.5849, 1.5849, 0.9199], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 279, Loss 0.381019\n",
      "Params: %f tensor([0.9535, 0.9535, 0.9728, 0.4535, 0.0535, 0.4728], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5844, 1.5844, 0.9196, 1.5844, 1.5844, 0.9196], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 280, Loss 0.380779\n",
      "Params: %f tensor([0.9533, 0.9533, 0.9728, 0.4533, 0.0533, 0.4728], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5838, 1.5838, 0.9192, 1.5838, 1.5838, 0.9192], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 281, Loss 0.380539\n",
      "Params: %f tensor([0.9532, 0.9532, 0.9727, 0.4532, 0.0532, 0.4727], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5832, 1.5832, 0.9188, 1.5832, 1.5832, 0.9188], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 282, Loss 0.380300\n",
      "Params: %f tensor([0.9530, 0.9530, 0.9726, 0.4530, 0.0530, 0.4726], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5826, 1.5826, 0.9184, 1.5826, 1.5826, 0.9184], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 283, Loss 0.380061\n",
      "Params: %f tensor([0.9529, 0.9529, 0.9725, 0.4529, 0.0529, 0.4725], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5821, 1.5821, 0.9181, 1.5821, 1.5821, 0.9181], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 284, Loss 0.379822\n",
      "Params: %f tensor([0.9527, 0.9527, 0.9724, 0.4527, 0.0527, 0.4724], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5815, 1.5815, 0.9177, 1.5815, 1.5815, 0.9177], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 285, Loss 0.379583\n",
      "Params: %f tensor([0.9525, 0.9525, 0.9723, 0.4525, 0.0525, 0.4723], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5809, 1.5809, 0.9173, 1.5809, 1.5809, 0.9173], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 286, Loss 0.379344\n",
      "Params: %f tensor([0.9524, 0.9524, 0.9722, 0.4524, 0.0524, 0.4722], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5803, 1.5803, 0.9170, 1.5803, 1.5803, 0.9170], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 287, Loss 0.379106\n",
      "Params: %f tensor([0.9522, 0.9522, 0.9721, 0.4522, 0.0522, 0.4721], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5798, 1.5798, 0.9166, 1.5798, 1.5798, 0.9166], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 288, Loss 0.378868\n",
      "Params: %f tensor([0.9521, 0.9521, 0.9720, 0.4521, 0.0521, 0.4720], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5792, 1.5792, 0.9162, 1.5792, 1.5792, 0.9162], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 289, Loss 0.378629\n",
      "Params: %f tensor([0.9519, 0.9519, 0.9719, 0.4519, 0.0519, 0.4719], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5786, 1.5786, 0.9158, 1.5786, 1.5786, 0.9158], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 290, Loss 0.378391\n",
      "Params: %f tensor([0.9518, 0.9518, 0.9718, 0.4518, 0.0518, 0.4718], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5781, 1.5781, 0.9155, 1.5781, 1.5781, 0.9155], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 291, Loss 0.378154\n",
      "Params: %f tensor([0.9516, 0.9516, 0.9717, 0.4516, 0.0516, 0.4717], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5775, 1.5775, 0.9151, 1.5775, 1.5775, 0.9151], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 292, Loss 0.377916\n",
      "Params: %f tensor([0.9514, 0.9514, 0.9717, 0.4514, 0.0514, 0.4717], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5769, 1.5769, 0.9147, 1.5769, 1.5769, 0.9147], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 293, Loss 0.377678\n",
      "Params: %f tensor([0.9513, 0.9513, 0.9716, 0.4513, 0.0513, 0.4716], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5763, 1.5763, 0.9144, 1.5763, 1.5763, 0.9144], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 294, Loss 0.377441\n",
      "Params: %f tensor([0.9511, 0.9511, 0.9715, 0.4511, 0.0511, 0.4715], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5758, 1.5758, 0.9140, 1.5758, 1.5758, 0.9140], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 295, Loss 0.377204\n",
      "Params: %f tensor([0.9510, 0.9510, 0.9714, 0.4510, 0.0510, 0.4714], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5752, 1.5752, 0.9136, 1.5752, 1.5752, 0.9136], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 296, Loss 0.376967\n",
      "Params: %f tensor([0.9508, 0.9508, 0.9713, 0.4508, 0.0508, 0.4713], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5746, 1.5746, 0.9133, 1.5746, 1.5746, 0.9133], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 297, Loss 0.376730\n",
      "Params: %f tensor([0.9507, 0.9507, 0.9712, 0.4507, 0.0507, 0.4712], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5741, 1.5741, 0.9129, 1.5741, 1.5741, 0.9129], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 298, Loss 0.376494\n",
      "Params: %f tensor([0.9505, 0.9505, 0.9711, 0.4505, 0.0505, 0.4711], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5735, 1.5735, 0.9125, 1.5735, 1.5735, 0.9125], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 299, Loss 0.376257\n",
      "Params: %f tensor([0.9503, 0.9503, 0.9710, 0.4503, 0.0503, 0.4710], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5729, 1.5729, 0.9121, 1.5729, 1.5729, 0.9121], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 300, Loss 0.376021\n",
      "Params: %f tensor([0.9502, 0.9502, 0.9709, 0.4502, 0.0502, 0.4709], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5724, 1.5724, 0.9118, 1.5724, 1.5724, 0.9118], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 301, Loss 0.375785\n",
      "Params: %f tensor([0.9500, 0.9500, 0.9708, 0.4500, 0.0500, 0.4708], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5718, 1.5718, 0.9114, 1.5718, 1.5718, 0.9114], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 302, Loss 0.375549\n",
      "Params: %f tensor([0.9499, 0.9499, 0.9707, 0.4499, 0.0499, 0.4707], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5712, 1.5712, 0.9110, 1.5712, 1.5712, 0.9110], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 303, Loss 0.375313\n",
      "Params: %f tensor([0.9497, 0.9497, 0.9707, 0.4497, 0.0497, 0.4707], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5707, 1.5707, 0.9107, 1.5707, 1.5707, 0.9107], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 304, Loss 0.375078\n",
      "Params: %f tensor([0.9496, 0.9496, 0.9706, 0.4496, 0.0496, 0.4706], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5701, 1.5701, 0.9103, 1.5701, 1.5701, 0.9103], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 305, Loss 0.374842\n",
      "Params: %f tensor([0.9494, 0.9494, 0.9705, 0.4494, 0.0494, 0.4705], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5695, 1.5695, 0.9099, 1.5695, 1.5695, 0.9099], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 306, Loss 0.374607\n",
      "Params: %f tensor([0.9492, 0.9492, 0.9704, 0.4492, 0.0492, 0.4704], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5689, 1.5689, 0.9096, 1.5689, 1.5689, 0.9096], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 307, Loss 0.374372\n",
      "Params: %f tensor([0.9491, 0.9491, 0.9703, 0.4491, 0.0491, 0.4703], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5684, 1.5684, 0.9092, 1.5684, 1.5684, 0.9092], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 308, Loss 0.374137\n",
      "Params: %f tensor([0.9489, 0.9489, 0.9702, 0.4489, 0.0489, 0.4702], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5678, 1.5678, 0.9088, 1.5678, 1.5678, 0.9088], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 309, Loss 0.373903\n",
      "Params: %f tensor([0.9488, 0.9488, 0.9701, 0.4488, 0.0488, 0.4701], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5672, 1.5672, 0.9084, 1.5672, 1.5672, 0.9084], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 310, Loss 0.373668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: %f tensor([0.9486, 0.9486, 0.9700, 0.4486, 0.0486, 0.4700], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5667, 1.5667, 0.9081, 1.5667, 1.5667, 0.9081], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 311, Loss 0.373434\n",
      "Params: %f tensor([0.9485, 0.9485, 0.9699, 0.4485, 0.0485, 0.4699], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5661, 1.5661, 0.9077, 1.5661, 1.5661, 0.9077], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 312, Loss 0.373199\n",
      "Params: %f tensor([0.9483, 0.9483, 0.9698, 0.4483, 0.0483, 0.4698], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5655, 1.5655, 0.9073, 1.5655, 1.5655, 0.9073], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 313, Loss 0.372965\n",
      "Params: %f tensor([0.9481, 0.9481, 0.9697, 0.4481, 0.0481, 0.4697], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5650, 1.5650, 0.9070, 1.5650, 1.5650, 0.9070], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 314, Loss 0.372732\n",
      "Params: %f tensor([0.9480, 0.9480, 0.9697, 0.4480, 0.0480, 0.4697], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5644, 1.5644, 0.9066, 1.5644, 1.5644, 0.9066], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 315, Loss 0.372498\n",
      "Params: %f tensor([0.9478, 0.9478, 0.9696, 0.4478, 0.0478, 0.4696], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5638, 1.5638, 0.9062, 1.5638, 1.5638, 0.9062], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 316, Loss 0.372264\n",
      "Params: %f tensor([0.9477, 0.9477, 0.9695, 0.4477, 0.0477, 0.4695], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5633, 1.5633, 0.9059, 1.5633, 1.5633, 0.9059], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 317, Loss 0.372031\n",
      "Params: %f tensor([0.9475, 0.9475, 0.9694, 0.4475, 0.0475, 0.4694], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5627, 1.5627, 0.9055, 1.5627, 1.5627, 0.9055], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 318, Loss 0.371798\n",
      "Params: %f tensor([0.9474, 0.9474, 0.9693, 0.4474, 0.0474, 0.4693], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5621, 1.5621, 0.9051, 1.5621, 1.5621, 0.9051], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 319, Loss 0.371565\n",
      "Params: %f tensor([0.9472, 0.9472, 0.9692, 0.4472, 0.0472, 0.4692], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5616, 1.5616, 0.9048, 1.5616, 1.5616, 0.9048], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 320, Loss 0.371332\n",
      "Params: %f tensor([0.9470, 0.9470, 0.9691, 0.4470, 0.0470, 0.4691], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5610, 1.5610, 0.9044, 1.5610, 1.5610, 0.9044], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 321, Loss 0.371099\n",
      "Params: %f tensor([0.9469, 0.9469, 0.9690, 0.4469, 0.0469, 0.4690], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5605, 1.5605, 0.9040, 1.5605, 1.5605, 0.9040], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 322, Loss 0.370867\n",
      "Params: %f tensor([0.9467, 0.9467, 0.9689, 0.4467, 0.0467, 0.4689], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5599, 1.5599, 0.9037, 1.5599, 1.5599, 0.9037], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 323, Loss 0.370635\n",
      "Params: %f tensor([0.9466, 0.9466, 0.9688, 0.4466, 0.0466, 0.4688], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5593, 1.5593, 0.9033, 1.5593, 1.5593, 0.9033], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 324, Loss 0.370402\n",
      "Params: %f tensor([0.9464, 0.9464, 0.9687, 0.4464, 0.0464, 0.4687], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5588, 1.5588, 0.9029, 1.5588, 1.5588, 0.9029], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 325, Loss 0.370170\n",
      "Params: %f tensor([0.9463, 0.9463, 0.9687, 0.4463, 0.0463, 0.4687], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5582, 1.5582, 0.9026, 1.5582, 1.5582, 0.9026], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 326, Loss 0.369939\n",
      "Params: %f tensor([0.9461, 0.9461, 0.9686, 0.4461, 0.0461, 0.4686], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5576, 1.5576, 0.9022, 1.5576, 1.5576, 0.9022], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 327, Loss 0.369707\n",
      "Params: %f tensor([0.9460, 0.9460, 0.9685, 0.4460, 0.0460, 0.4685], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5571, 1.5571, 0.9018, 1.5571, 1.5571, 0.9018], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 328, Loss 0.369475\n",
      "Params: %f tensor([0.9458, 0.9458, 0.9684, 0.4458, 0.0458, 0.4684], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5565, 1.5565, 0.9015, 1.5565, 1.5565, 0.9015], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 329, Loss 0.369244\n",
      "Params: %f tensor([0.9456, 0.9456, 0.9683, 0.4456, 0.0456, 0.4683], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5559, 1.5559, 0.9011, 1.5559, 1.5559, 0.9011], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 330, Loss 0.369013\n",
      "Params: %f tensor([0.9455, 0.9455, 0.9682, 0.4455, 0.0455, 0.4682], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5554, 1.5554, 0.9007, 1.5554, 1.5554, 0.9007], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 331, Loss 0.368782\n",
      "Params: %f tensor([0.9453, 0.9453, 0.9681, 0.4453, 0.0453, 0.4681], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5548, 1.5548, 0.9004, 1.5548, 1.5548, 0.9004], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 332, Loss 0.368551\n",
      "Params: %f tensor([0.9452, 0.9452, 0.9680, 0.4452, 0.0452, 0.4680], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5543, 1.5543, 0.9000, 1.5543, 1.5543, 0.9000], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 333, Loss 0.368321\n",
      "Params: %f tensor([0.9450, 0.9450, 0.9679, 0.4450, 0.0450, 0.4679], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5537, 1.5537, 0.8996, 1.5537, 1.5537, 0.8996], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 334, Loss 0.368090\n",
      "Params: %f tensor([0.9449, 0.9449, 0.9678, 0.4449, 0.0449, 0.4678], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5531, 1.5531, 0.8993, 1.5531, 1.5531, 0.8993], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 335, Loss 0.367860\n",
      "Params: %f tensor([0.9447, 0.9447, 0.9678, 0.4447, 0.0447, 0.4678], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5526, 1.5526, 0.8989, 1.5526, 1.5526, 0.8989], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 336, Loss 0.367630\n",
      "Params: %f tensor([0.9446, 0.9446, 0.9677, 0.4446, 0.0446, 0.4677], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5520, 1.5520, 0.8985, 1.5520, 1.5520, 0.8985], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 337, Loss 0.367400\n",
      "Params: %f tensor([0.9444, 0.9444, 0.9676, 0.4444, 0.0444, 0.4676], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5514, 1.5514, 0.8982, 1.5514, 1.5514, 0.8982], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 338, Loss 0.367170\n",
      "Params: %f tensor([0.9442, 0.9442, 0.9675, 0.4442, 0.0442, 0.4675], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5509, 1.5509, 0.8978, 1.5509, 1.5509, 0.8978], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 339, Loss 0.366940\n",
      "Params: %f tensor([0.9441, 0.9441, 0.9674, 0.4441, 0.0441, 0.4674], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5503, 1.5503, 0.8974, 1.5503, 1.5503, 0.8974], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 340, Loss 0.366711\n",
      "Params: %f tensor([0.9439, 0.9439, 0.9673, 0.4439, 0.0439, 0.4673], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5498, 1.5498, 0.8971, 1.5498, 1.5498, 0.8971], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 341, Loss 0.366482\n",
      "Params: %f tensor([0.9438, 0.9438, 0.9672, 0.4438, 0.0438, 0.4672], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5492, 1.5492, 0.8967, 1.5492, 1.5492, 0.8967], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 342, Loss 0.366252\n",
      "Params: %f tensor([0.9436, 0.9436, 0.9671, 0.4436, 0.0436, 0.4671], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5486, 1.5486, 0.8964, 1.5486, 1.5486, 0.8964], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 343, Loss 0.366023\n",
      "Params: %f tensor([0.9435, 0.9435, 0.9670, 0.4435, 0.0435, 0.4670], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5481, 1.5481, 0.8960, 1.5481, 1.5481, 0.8960], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 344, Loss 0.365795\n",
      "Params: %f tensor([0.9433, 0.9433, 0.9670, 0.4433, 0.0433, 0.4670], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5475, 1.5475, 0.8956, 1.5475, 1.5475, 0.8956], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 345, Loss 0.365566\n",
      "Params: %f tensor([0.9432, 0.9432, 0.9669, 0.4432, 0.0432, 0.4669], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5470, 1.5470, 0.8953, 1.5470, 1.5470, 0.8953], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 346, Loss 0.365338\n",
      "Params: %f tensor([0.9430, 0.9430, 0.9668, 0.4430, 0.0430, 0.4668], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5464, 1.5464, 0.8949, 1.5464, 1.5464, 0.8949], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 347, Loss 0.365109\n",
      "Params: %f tensor([0.9429, 0.9429, 0.9667, 0.4429, 0.0429, 0.4667], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5458, 1.5458, 0.8945, 1.5458, 1.5458, 0.8945], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 348, Loss 0.364881\n",
      "Params: %f tensor([0.9427, 0.9427, 0.9666, 0.4427, 0.0427, 0.4666], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5453, 1.5453, 0.8942, 1.5453, 1.5453, 0.8942], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 349, Loss 0.364653\n",
      "Params: %f tensor([0.9425, 0.9425, 0.9665, 0.4425, 0.0425, 0.4665], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5447, 1.5447, 0.8938, 1.5447, 1.5447, 0.8938], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 350, Loss 0.364425\n",
      "Params: %f tensor([0.9424, 0.9424, 0.9664, 0.4424, 0.0424, 0.4664], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5442, 1.5442, 0.8934, 1.5442, 1.5442, 0.8934], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 351, Loss 0.364198\n",
      "Params: %f tensor([0.9422, 0.9422, 0.9663, 0.4422, 0.0422, 0.4663], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5436, 1.5436, 0.8931, 1.5436, 1.5436, 0.8931], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 352, Loss 0.363970\n",
      "Params: %f tensor([0.9421, 0.9421, 0.9662, 0.4421, 0.0421, 0.4662], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5430, 1.5430, 0.8927, 1.5430, 1.5430, 0.8927], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 353, Loss 0.363743\n",
      "Params: %f tensor([0.9419, 0.9419, 0.9661, 0.4419, 0.0419, 0.4661], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5425, 1.5425, 0.8924, 1.5425, 1.5425, 0.8924], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 354, Loss 0.363516\n",
      "Params: %f tensor([0.9418, 0.9418, 0.9661, 0.4418, 0.0418, 0.4661], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5419, 1.5419, 0.8920, 1.5419, 1.5419, 0.8920], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 355, Loss 0.363289\n",
      "Params: %f tensor([0.9416, 0.9416, 0.9660, 0.4416, 0.0416, 0.4660], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5414, 1.5414, 0.8916, 1.5414, 1.5414, 0.8916], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 356, Loss 0.363062\n",
      "Params: %f tensor([0.9415, 0.9415, 0.9659, 0.4415, 0.0415, 0.4659], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5408, 1.5408, 0.8913, 1.5408, 1.5408, 0.8913], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 357, Loss 0.362835\n",
      "Params: %f tensor([0.9413, 0.9413, 0.9658, 0.4413, 0.0413, 0.4658], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5403, 1.5403, 0.8909, 1.5403, 1.5403, 0.8909], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 358, Loss 0.362609\n",
      "Params: %f tensor([0.9412, 0.9412, 0.9657, 0.4412, 0.0412, 0.4657], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5397, 1.5397, 0.8905, 1.5397, 1.5397, 0.8905], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 359, Loss 0.362383\n",
      "Params: %f tensor([0.9410, 0.9410, 0.9656, 0.4410, 0.0410, 0.4656], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5391, 1.5391, 0.8902, 1.5391, 1.5391, 0.8902], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 360, Loss 0.362156\n",
      "Params: %f tensor([0.9409, 0.9409, 0.9655, 0.4409, 0.0409, 0.4655], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5386, 1.5386, 0.8898, 1.5386, 1.5386, 0.8898], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 361, Loss 0.361930\n",
      "Params: %f tensor([0.9407, 0.9407, 0.9654, 0.4407, 0.0407, 0.4654], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5380, 1.5380, 0.8895, 1.5380, 1.5380, 0.8895], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 362, Loss 0.361705\n",
      "Params: %f tensor([0.9405, 0.9405, 0.9653, 0.4405, 0.0405, 0.4653], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5375, 1.5375, 0.8891, 1.5375, 1.5375, 0.8891], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 363, Loss 0.361479\n",
      "Params: %f tensor([0.9404, 0.9404, 0.9653, 0.4404, 0.0404, 0.4653], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5369, 1.5369, 0.8887, 1.5369, 1.5369, 0.8887], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 364, Loss 0.361254\n",
      "Params: %f tensor([0.9402, 0.9402, 0.9652, 0.4402, 0.0402, 0.4652], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5364, 1.5364, 0.8884, 1.5364, 1.5364, 0.8884], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 365, Loss 0.361028\n",
      "Params: %f tensor([0.9401, 0.9401, 0.9651, 0.4401, 0.0401, 0.4651], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5358, 1.5358, 0.8880, 1.5358, 1.5358, 0.8880], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 366, Loss 0.360803\n",
      "Params: %f tensor([0.9399, 0.9399, 0.9650, 0.4399, 0.0399, 0.4650], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5352, 1.5352, 0.8877, 1.5352, 1.5352, 0.8877], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 367, Loss 0.360578\n",
      "Params: %f tensor([0.9398, 0.9398, 0.9649, 0.4398, 0.0398, 0.4649], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad: %f tensor([1.5347, 1.5347, 0.8873, 1.5347, 1.5347, 0.8873], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 368, Loss 0.360353\n",
      "Params: %f tensor([0.9396, 0.9396, 0.9648, 0.4396, 0.0396, 0.4648], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5341, 1.5341, 0.8869, 1.5341, 1.5341, 0.8869], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 369, Loss 0.360129\n",
      "Params: %f tensor([0.9395, 0.9395, 0.9647, 0.4395, 0.0395, 0.4647], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5336, 1.5336, 0.8866, 1.5336, 1.5336, 0.8866], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 370, Loss 0.359904\n",
      "Params: %f tensor([0.9393, 0.9393, 0.9646, 0.4393, 0.0393, 0.4646], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5330, 1.5330, 0.8862, 1.5330, 1.5330, 0.8862], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 371, Loss 0.359680\n",
      "Params: %f tensor([0.9392, 0.9392, 0.9645, 0.4392, 0.0392, 0.4645], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5325, 1.5325, 0.8858, 1.5325, 1.5325, 0.8858], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 372, Loss 0.359456\n",
      "Params: %f tensor([0.9390, 0.9390, 0.9645, 0.4390, 0.0390, 0.4645], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5319, 1.5319, 0.8855, 1.5319, 1.5319, 0.8855], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 373, Loss 0.359232\n",
      "Params: %f tensor([0.9389, 0.9389, 0.9644, 0.4389, 0.0389, 0.4644], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5314, 1.5314, 0.8851, 1.5314, 1.5314, 0.8851], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 374, Loss 0.359008\n",
      "Params: %f tensor([0.9387, 0.9387, 0.9643, 0.4387, 0.0387, 0.4643], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5308, 1.5308, 0.8848, 1.5308, 1.5308, 0.8848], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 375, Loss 0.358784\n",
      "Params: %f tensor([0.9385, 0.9385, 0.9642, 0.4385, 0.0385, 0.4642], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5303, 1.5303, 0.8844, 1.5303, 1.5303, 0.8844], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 376, Loss 0.358560\n",
      "Params: %f tensor([0.9384, 0.9384, 0.9641, 0.4384, 0.0384, 0.4641], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5297, 1.5297, 0.8840, 1.5297, 1.5297, 0.8840], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 377, Loss 0.358337\n",
      "Params: %f tensor([0.9382, 0.9382, 0.9640, 0.4382, 0.0382, 0.4640], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5291, 1.5291, 0.8837, 1.5291, 1.5291, 0.8837], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 378, Loss 0.358114\n",
      "Params: %f tensor([0.9381, 0.9381, 0.9639, 0.4381, 0.0381, 0.4639], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5286, 1.5286, 0.8833, 1.5286, 1.5286, 0.8833], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 379, Loss 0.357891\n",
      "Params: %f tensor([0.9379, 0.9379, 0.9638, 0.4379, 0.0379, 0.4638], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5280, 1.5280, 0.8830, 1.5280, 1.5280, 0.8830], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 380, Loss 0.357668\n",
      "Params: %f tensor([0.9378, 0.9378, 0.9638, 0.4378, 0.0378, 0.4638], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5275, 1.5275, 0.8826, 1.5275, 1.5275, 0.8826], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 381, Loss 0.357445\n",
      "Params: %f tensor([0.9376, 0.9376, 0.9637, 0.4376, 0.0376, 0.4637], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5269, 1.5269, 0.8822, 1.5269, 1.5269, 0.8822], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 382, Loss 0.357223\n",
      "Params: %f tensor([0.9375, 0.9375, 0.9636, 0.4375, 0.0375, 0.4636], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5264, 1.5264, 0.8819, 1.5264, 1.5264, 0.8819], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 383, Loss 0.357000\n",
      "Params: %f tensor([0.9373, 0.9373, 0.9635, 0.4373, 0.0373, 0.4635], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5258, 1.5258, 0.8815, 1.5258, 1.5258, 0.8815], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 384, Loss 0.356778\n",
      "Params: %f tensor([0.9372, 0.9372, 0.9634, 0.4372, 0.0372, 0.4634], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5253, 1.5253, 0.8812, 1.5253, 1.5253, 0.8812], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 385, Loss 0.356556\n",
      "Params: %f tensor([0.9370, 0.9370, 0.9633, 0.4370, 0.0370, 0.4633], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5247, 1.5247, 0.8808, 1.5247, 1.5247, 0.8808], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 386, Loss 0.356334\n",
      "Params: %f tensor([0.9369, 0.9369, 0.9632, 0.4369, 0.0369, 0.4632], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5242, 1.5242, 0.8805, 1.5242, 1.5242, 0.8805], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 387, Loss 0.356112\n",
      "Params: %f tensor([0.9367, 0.9367, 0.9631, 0.4367, 0.0367, 0.4631], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5236, 1.5236, 0.8801, 1.5236, 1.5236, 0.8801], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 388, Loss 0.355891\n",
      "Params: %f tensor([0.9366, 0.9366, 0.9630, 0.4366, 0.0366, 0.4630], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5231, 1.5231, 0.8797, 1.5231, 1.5231, 0.8797], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 389, Loss 0.355669\n",
      "Params: %f tensor([0.9364, 0.9364, 0.9630, 0.4364, 0.0364, 0.4630], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5225, 1.5225, 0.8794, 1.5225, 1.5225, 0.8794], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 390, Loss 0.355448\n",
      "Params: %f tensor([0.9363, 0.9363, 0.9629, 0.4363, 0.0363, 0.4629], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5220, 1.5220, 0.8790, 1.5220, 1.5220, 0.8790], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 391, Loss 0.355227\n",
      "Params: %f tensor([0.9361, 0.9361, 0.9628, 0.4361, 0.0361, 0.4628], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5214, 1.5214, 0.8787, 1.5214, 1.5214, 0.8787], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 392, Loss 0.355006\n",
      "Params: %f tensor([0.9360, 0.9360, 0.9627, 0.4360, 0.0360, 0.4627], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5209, 1.5209, 0.8783, 1.5209, 1.5209, 0.8783], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 393, Loss 0.354785\n",
      "Params: %f tensor([0.9358, 0.9358, 0.9626, 0.4358, 0.0358, 0.4626], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5203, 1.5203, 0.8780, 1.5203, 1.5203, 0.8780], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 394, Loss 0.354565\n",
      "Params: %f tensor([0.9357, 0.9357, 0.9625, 0.4357, 0.0357, 0.4625], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5198, 1.5198, 0.8776, 1.5198, 1.5198, 0.8776], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 395, Loss 0.354344\n",
      "Params: %f tensor([0.9355, 0.9355, 0.9624, 0.4355, 0.0355, 0.4624], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5192, 1.5192, 0.8772, 1.5192, 1.5192, 0.8772], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 396, Loss 0.354124\n",
      "Params: %f tensor([0.9353, 0.9353, 0.9623, 0.4353, 0.0353, 0.4623], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5187, 1.5187, 0.8769, 1.5187, 1.5187, 0.8769], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 397, Loss 0.353904\n",
      "Params: %f tensor([0.9352, 0.9352, 0.9623, 0.4352, 0.0352, 0.4623], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5181, 1.5181, 0.8765, 1.5181, 1.5181, 0.8765], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 398, Loss 0.353684\n",
      "Params: %f tensor([0.9350, 0.9350, 0.9622, 0.4350, 0.0350, 0.4622], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5176, 1.5176, 0.8762, 1.5176, 1.5176, 0.8762], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 399, Loss 0.353464\n",
      "Params: %f tensor([0.9349, 0.9349, 0.9621, 0.4349, 0.0349, 0.4621], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5170, 1.5170, 0.8758, 1.5170, 1.5170, 0.8758], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 400, Loss 0.353244\n",
      "Params: %f tensor([0.9347, 0.9347, 0.9620, 0.4347, 0.0347, 0.4620], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5165, 1.5165, 0.8755, 1.5165, 1.5165, 0.8755], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 401, Loss 0.353025\n",
      "Params: %f tensor([0.9346, 0.9346, 0.9619, 0.4346, 0.0346, 0.4619], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5159, 1.5159, 0.8751, 1.5159, 1.5159, 0.8751], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 402, Loss 0.352806\n",
      "Params: %f tensor([0.9344, 0.9344, 0.9618, 0.4344, 0.0344, 0.4618], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5154, 1.5154, 0.8747, 1.5154, 1.5154, 0.8747], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 403, Loss 0.352586\n",
      "Params: %f tensor([0.9343, 0.9343, 0.9617, 0.4343, 0.0343, 0.4617], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5148, 1.5148, 0.8744, 1.5148, 1.5148, 0.8744], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 404, Loss 0.352367\n",
      "Params: %f tensor([0.9341, 0.9341, 0.9616, 0.4341, 0.0341, 0.4616], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5143, 1.5143, 0.8740, 1.5143, 1.5143, 0.8740], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 405, Loss 0.352149\n",
      "Params: %f tensor([0.9340, 0.9340, 0.9616, 0.4340, 0.0340, 0.4616], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5137, 1.5137, 0.8737, 1.5137, 1.5137, 0.8737], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 406, Loss 0.351930\n",
      "Params: %f tensor([0.9338, 0.9338, 0.9615, 0.4338, 0.0338, 0.4615], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5132, 1.5132, 0.8733, 1.5132, 1.5132, 0.8733], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 407, Loss 0.351711\n",
      "Params: %f tensor([0.9337, 0.9337, 0.9614, 0.4337, 0.0337, 0.4614], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5126, 1.5126, 0.8730, 1.5126, 1.5126, 0.8730], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 408, Loss 0.351493\n",
      "Params: %f tensor([0.9335, 0.9335, 0.9613, 0.4335, 0.0335, 0.4613], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5121, 1.5121, 0.8726, 1.5121, 1.5121, 0.8726], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 409, Loss 0.351275\n",
      "Params: %f tensor([0.9334, 0.9334, 0.9612, 0.4334, 0.0334, 0.4612], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5115, 1.5115, 0.8722, 1.5115, 1.5115, 0.8722], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 410, Loss 0.351057\n",
      "Params: %f tensor([0.9332, 0.9332, 0.9611, 0.4332, 0.0332, 0.4611], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5110, 1.5110, 0.8719, 1.5110, 1.5110, 0.8719], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 411, Loss 0.350839\n",
      "Params: %f tensor([0.9331, 0.9331, 0.9610, 0.4331, 0.0331, 0.4610], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5105, 1.5105, 0.8715, 1.5105, 1.5105, 0.8715], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 412, Loss 0.350621\n",
      "Params: %f tensor([0.9329, 0.9329, 0.9609, 0.4329, 0.0329, 0.4609], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5099, 1.5099, 0.8712, 1.5099, 1.5099, 0.8712], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 413, Loss 0.350404\n",
      "Params: %f tensor([0.9328, 0.9328, 0.9609, 0.4328, 0.0328, 0.4609], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5094, 1.5094, 0.8708, 1.5094, 1.5094, 0.8708], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 414, Loss 0.350186\n",
      "Params: %f tensor([0.9326, 0.9326, 0.9608, 0.4326, 0.0326, 0.4608], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5088, 1.5088, 0.8705, 1.5088, 1.5088, 0.8705], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 415, Loss 0.349969\n",
      "Params: %f tensor([0.9325, 0.9325, 0.9607, 0.4325, 0.0325, 0.4607], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5083, 1.5083, 0.8701, 1.5083, 1.5083, 0.8701], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 416, Loss 0.349752\n",
      "Params: %f tensor([0.9323, 0.9323, 0.9606, 0.4323, 0.0323, 0.4606], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5077, 1.5077, 0.8698, 1.5077, 1.5077, 0.8698], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 417, Loss 0.349535\n",
      "Params: %f tensor([0.9322, 0.9322, 0.9605, 0.4322, 0.0322, 0.4605], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5072, 1.5072, 0.8694, 1.5072, 1.5072, 0.8694], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 418, Loss 0.349318\n",
      "Params: %f tensor([0.9320, 0.9320, 0.9604, 0.4320, 0.0320, 0.4604], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5066, 1.5066, 0.8691, 1.5066, 1.5066, 0.8691], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 419, Loss 0.349101\n",
      "Params: %f tensor([0.9319, 0.9319, 0.9603, 0.4319, 0.0319, 0.4603], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5061, 1.5061, 0.8687, 1.5061, 1.5061, 0.8687], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 420, Loss 0.348885\n",
      "Params: %f tensor([0.9317, 0.9317, 0.9602, 0.4317, 0.0317, 0.4602], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5055, 1.5055, 0.8683, 1.5055, 1.5055, 0.8683], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 421, Loss 0.348669\n",
      "Params: %f tensor([0.9316, 0.9316, 0.9602, 0.4316, 0.0316, 0.4602], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5050, 1.5050, 0.8680, 1.5050, 1.5050, 0.8680], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 422, Loss 0.348452\n",
      "Params: %f tensor([0.9314, 0.9314, 0.9601, 0.4314, 0.0314, 0.4601], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5045, 1.5045, 0.8676, 1.5045, 1.5045, 0.8676], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 423, Loss 0.348236\n",
      "Params: %f tensor([0.9313, 0.9313, 0.9600, 0.4313, 0.0313, 0.4600], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5039, 1.5039, 0.8673, 1.5039, 1.5039, 0.8673], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 424, Loss 0.348021\n",
      "Params: %f tensor([0.9311, 0.9311, 0.9599, 0.4311, 0.0311, 0.4599], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5034, 1.5034, 0.8669, 1.5034, 1.5034, 0.8669], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 425, Loss 0.347805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: %f tensor([0.9310, 0.9310, 0.9598, 0.4310, 0.0310, 0.4598], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5028, 1.5028, 0.8666, 1.5028, 1.5028, 0.8666], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 426, Loss 0.347589\n",
      "Params: %f tensor([0.9308, 0.9308, 0.9597, 0.4308, 0.0308, 0.4597], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5023, 1.5023, 0.8662, 1.5023, 1.5023, 0.8662], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 427, Loss 0.347374\n",
      "Params: %f tensor([0.9307, 0.9307, 0.9596, 0.4307, 0.0307, 0.4596], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5017, 1.5017, 0.8659, 1.5017, 1.5017, 0.8659], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 428, Loss 0.347159\n",
      "Params: %f tensor([0.9305, 0.9305, 0.9596, 0.4305, 0.0305, 0.4596], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5012, 1.5012, 0.8655, 1.5012, 1.5012, 0.8655], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 429, Loss 0.346944\n",
      "Params: %f tensor([0.9304, 0.9304, 0.9595, 0.4304, 0.0304, 0.4595], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5006, 1.5006, 0.8652, 1.5006, 1.5006, 0.8652], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 430, Loss 0.346729\n",
      "Params: %f tensor([0.9302, 0.9302, 0.9594, 0.4302, 0.0302, 0.4594], dtype=torch.float64)\n",
      "Grad: %f tensor([1.5001, 1.5001, 0.8648, 1.5001, 1.5001, 0.8648], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 431, Loss 0.346514\n",
      "Params: %f tensor([0.9301, 0.9301, 0.9593, 0.4301, 0.0301, 0.4593], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4996, 1.4996, 0.8645, 1.4996, 1.4996, 0.8645], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 432, Loss 0.346300\n",
      "Params: %f tensor([0.9299, 0.9299, 0.9592, 0.4299, 0.0299, 0.4592], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4990, 1.4990, 0.8641, 1.4990, 1.4990, 0.8641], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 433, Loss 0.346085\n",
      "Params: %f tensor([0.9298, 0.9298, 0.9591, 0.4298, 0.0298, 0.4591], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4985, 1.4985, 0.8638, 1.4985, 1.4985, 0.8638], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 434, Loss 0.345871\n",
      "Params: %f tensor([0.9296, 0.9296, 0.9590, 0.4296, 0.0296, 0.4590], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4979, 1.4979, 0.8634, 1.4979, 1.4979, 0.8634], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 435, Loss 0.345657\n",
      "Params: %f tensor([0.9295, 0.9295, 0.9590, 0.4295, 0.0295, 0.4590], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4974, 1.4974, 0.8630, 1.4974, 1.4974, 0.8630], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 436, Loss 0.345443\n",
      "Params: %f tensor([0.9293, 0.9293, 0.9589, 0.4293, 0.0293, 0.4589], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4969, 1.4969, 0.8627, 1.4969, 1.4969, 0.8627], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 437, Loss 0.345229\n",
      "Params: %f tensor([0.9292, 0.9292, 0.9588, 0.4292, 0.0292, 0.4588], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4963, 1.4963, 0.8623, 1.4963, 1.4963, 0.8623], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 438, Loss 0.345015\n",
      "Params: %f tensor([0.9290, 0.9290, 0.9587, 0.4290, 0.0290, 0.4587], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4958, 1.4958, 0.8620, 1.4958, 1.4958, 0.8620], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 439, Loss 0.344802\n",
      "Params: %f tensor([0.9289, 0.9289, 0.9586, 0.4289, 0.0289, 0.4586], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4952, 1.4952, 0.8616, 1.4952, 1.4952, 0.8616], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 440, Loss 0.344589\n",
      "Params: %f tensor([0.9287, 0.9287, 0.9585, 0.4287, 0.0287, 0.4585], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4947, 1.4947, 0.8613, 1.4947, 1.4947, 0.8613], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 441, Loss 0.344375\n",
      "Params: %f tensor([0.9286, 0.9286, 0.9584, 0.4286, 0.0286, 0.4584], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4941, 1.4941, 0.8609, 1.4941, 1.4941, 0.8609], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 442, Loss 0.344162\n",
      "Params: %f tensor([0.9284, 0.9284, 0.9583, 0.4284, 0.0284, 0.4583], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4936, 1.4936, 0.8606, 1.4936, 1.4936, 0.8606], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 443, Loss 0.343949\n",
      "Params: %f tensor([0.9283, 0.9283, 0.9583, 0.4283, 0.0283, 0.4583], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4931, 1.4931, 0.8602, 1.4931, 1.4931, 0.8602], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 444, Loss 0.343737\n",
      "Params: %f tensor([0.9281, 0.9281, 0.9582, 0.4281, 0.0281, 0.4582], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4925, 1.4925, 0.8599, 1.4925, 1.4925, 0.8599], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 445, Loss 0.343524\n",
      "Params: %f tensor([0.9280, 0.9280, 0.9581, 0.4280, 0.0280, 0.4581], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4920, 1.4920, 0.8595, 1.4920, 1.4920, 0.8595], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 446, Loss 0.343312\n",
      "Params: %f tensor([0.9278, 0.9278, 0.9580, 0.4278, 0.0278, 0.4580], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4914, 1.4914, 0.8592, 1.4914, 1.4914, 0.8592], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 447, Loss 0.343099\n",
      "Params: %f tensor([0.9277, 0.9277, 0.9579, 0.4277, 0.0277, 0.4579], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4909, 1.4909, 0.8588, 1.4909, 1.4909, 0.8588], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 448, Loss 0.342887\n",
      "Params: %f tensor([0.9275, 0.9275, 0.9578, 0.4275, 0.0275, 0.4578], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4904, 1.4904, 0.8585, 1.4904, 1.4904, 0.8585], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 449, Loss 0.342675\n",
      "Params: %f tensor([0.9274, 0.9274, 0.9577, 0.4274, 0.0274, 0.4577], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4898, 1.4898, 0.8581, 1.4898, 1.4898, 0.8581], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 450, Loss 0.342464\n",
      "Params: %f tensor([0.9272, 0.9272, 0.9577, 0.4272, 0.0272, 0.4577], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4893, 1.4893, 0.8578, 1.4893, 1.4893, 0.8578], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 451, Loss 0.342252\n",
      "Params: %f tensor([0.9271, 0.9271, 0.9576, 0.4271, 0.0271, 0.4576], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4888, 1.4888, 0.8574, 1.4888, 1.4888, 0.8574], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 452, Loss 0.342041\n",
      "Params: %f tensor([0.9269, 0.9269, 0.9575, 0.4269, 0.0269, 0.4575], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4882, 1.4882, 0.8571, 1.4882, 1.4882, 0.8571], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 453, Loss 0.341829\n",
      "Params: %f tensor([0.9268, 0.9268, 0.9574, 0.4268, 0.0268, 0.4574], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4877, 1.4877, 0.8567, 1.4877, 1.4877, 0.8567], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 454, Loss 0.341618\n",
      "Params: %f tensor([0.9266, 0.9266, 0.9573, 0.4266, 0.0266, 0.4573], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4871, 1.4871, 0.8564, 1.4871, 1.4871, 0.8564], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 455, Loss 0.341407\n",
      "Params: %f tensor([0.9265, 0.9265, 0.9572, 0.4265, 0.0265, 0.4572], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4866, 1.4866, 0.8560, 1.4866, 1.4866, 0.8560], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 456, Loss 0.341196\n",
      "Params: %f tensor([0.9263, 0.9263, 0.9571, 0.4263, 0.0263, 0.4571], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4861, 1.4861, 0.8557, 1.4861, 1.4861, 0.8557], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 457, Loss 0.340985\n",
      "Params: %f tensor([0.9262, 0.9262, 0.9571, 0.4262, 0.0262, 0.4571], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4855, 1.4855, 0.8553, 1.4855, 1.4855, 0.8553], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 458, Loss 0.340775\n",
      "Params: %f tensor([0.9260, 0.9260, 0.9570, 0.4260, 0.0260, 0.4570], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4850, 1.4850, 0.8550, 1.4850, 1.4850, 0.8550], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 459, Loss 0.340564\n",
      "Params: %f tensor([0.9259, 0.9259, 0.9569, 0.4259, 0.0259, 0.4569], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4844, 1.4844, 0.8546, 1.4844, 1.4844, 0.8546], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 460, Loss 0.340354\n",
      "Params: %f tensor([0.9257, 0.9257, 0.9568, 0.4257, 0.0257, 0.4568], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4839, 1.4839, 0.8543, 1.4839, 1.4839, 0.8543], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 461, Loss 0.340144\n",
      "Params: %f tensor([0.9256, 0.9256, 0.9567, 0.4256, 0.0256, 0.4567], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4834, 1.4834, 0.8539, 1.4834, 1.4834, 0.8539], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 462, Loss 0.339934\n",
      "Params: %f tensor([0.9254, 0.9254, 0.9566, 0.4254, 0.0254, 0.4566], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4828, 1.4828, 0.8536, 1.4828, 1.4828, 0.8536], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 463, Loss 0.339724\n",
      "Params: %f tensor([0.9253, 0.9253, 0.9565, 0.4253, 0.0253, 0.4565], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4823, 1.4823, 0.8532, 1.4823, 1.4823, 0.8532], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 464, Loss 0.339515\n",
      "Params: %f tensor([0.9251, 0.9251, 0.9565, 0.4251, 0.0251, 0.4565], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4818, 1.4818, 0.8529, 1.4818, 1.4818, 0.8529], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 465, Loss 0.339305\n",
      "Params: %f tensor([0.9250, 0.9250, 0.9564, 0.4250, 0.0250, 0.4564], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4812, 1.4812, 0.8525, 1.4812, 1.4812, 0.8525], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 466, Loss 0.339096\n",
      "Params: %f tensor([0.9249, 0.9249, 0.9563, 0.4249, 0.0249, 0.4563], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4807, 1.4807, 0.8522, 1.4807, 1.4807, 0.8522], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 467, Loss 0.338887\n",
      "Params: %f tensor([0.9247, 0.9247, 0.9562, 0.4247, 0.0247, 0.4562], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4802, 1.4802, 0.8518, 1.4802, 1.4802, 0.8518], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 468, Loss 0.338678\n",
      "Params: %f tensor([0.9246, 0.9246, 0.9561, 0.4246, 0.0246, 0.4561], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4796, 1.4796, 0.8515, 1.4796, 1.4796, 0.8515], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 469, Loss 0.338469\n",
      "Params: %f tensor([0.9244, 0.9244, 0.9560, 0.4244, 0.0244, 0.4560], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4791, 1.4791, 0.8511, 1.4791, 1.4791, 0.8511], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 470, Loss 0.338260\n",
      "Params: %f tensor([0.9243, 0.9243, 0.9560, 0.4243, 0.0243, 0.4560], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4786, 1.4786, 0.8508, 1.4786, 1.4786, 0.8508], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 471, Loss 0.338052\n",
      "Params: %f tensor([0.9241, 0.9241, 0.9559, 0.4241, 0.0241, 0.4559], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4780, 1.4780, 0.8505, 1.4780, 1.4780, 0.8505], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 472, Loss 0.337843\n",
      "Params: %f tensor([0.9240, 0.9240, 0.9558, 0.4240, 0.0240, 0.4558], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4775, 1.4775, 0.8501, 1.4775, 1.4775, 0.8501], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 473, Loss 0.337635\n",
      "Params: %f tensor([0.9238, 0.9238, 0.9557, 0.4238, 0.0238, 0.4557], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4769, 1.4769, 0.8498, 1.4769, 1.4769, 0.8498], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 474, Loss 0.337427\n",
      "Params: %f tensor([0.9237, 0.9237, 0.9556, 0.4237, 0.0237, 0.4556], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4764, 1.4764, 0.8494, 1.4764, 1.4764, 0.8494], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 475, Loss 0.337219\n",
      "Params: %f tensor([0.9235, 0.9235, 0.9555, 0.4235, 0.0235, 0.4555], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4759, 1.4759, 0.8491, 1.4759, 1.4759, 0.8491], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 476, Loss 0.337011\n",
      "Params: %f tensor([0.9234, 0.9234, 0.9554, 0.4234, 0.0234, 0.4554], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4753, 1.4753, 0.8487, 1.4753, 1.4753, 0.8487], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 477, Loss 0.336803\n",
      "Params: %f tensor([0.9232, 0.9232, 0.9554, 0.4232, 0.0232, 0.4554], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4748, 1.4748, 0.8484, 1.4748, 1.4748, 0.8484], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 478, Loss 0.336596\n",
      "Params: %f tensor([0.9231, 0.9231, 0.9553, 0.4231, 0.0231, 0.4553], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4743, 1.4743, 0.8480, 1.4743, 1.4743, 0.8480], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 479, Loss 0.336388\n",
      "Params: %f tensor([0.9229, 0.9229, 0.9552, 0.4229, 0.0229, 0.4552], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4737, 1.4737, 0.8477, 1.4737, 1.4737, 0.8477], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 480, Loss 0.336181\n",
      "Params: %f tensor([0.9228, 0.9228, 0.9551, 0.4228, 0.0228, 0.4551], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad: %f tensor([1.4732, 1.4732, 0.8473, 1.4732, 1.4732, 0.8473], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 481, Loss 0.335974\n",
      "Params: %f tensor([0.9226, 0.9226, 0.9550, 0.4226, 0.0226, 0.4550], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4727, 1.4727, 0.8470, 1.4727, 1.4727, 0.8470], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 482, Loss 0.335767\n",
      "Params: %f tensor([0.9225, 0.9225, 0.9549, 0.4225, 0.0225, 0.4549], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4721, 1.4721, 0.8466, 1.4721, 1.4721, 0.8466], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 483, Loss 0.335561\n",
      "Params: %f tensor([0.9223, 0.9223, 0.9548, 0.4223, 0.0223, 0.4548], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4716, 1.4716, 0.8463, 1.4716, 1.4716, 0.8463], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 484, Loss 0.335354\n",
      "Params: %f tensor([0.9222, 0.9222, 0.9548, 0.4222, 0.0222, 0.4548], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4711, 1.4711, 0.8459, 1.4711, 1.4711, 0.8459], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 485, Loss 0.335147\n",
      "Params: %f tensor([0.9221, 0.9221, 0.9547, 0.4221, 0.0221, 0.4547], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4706, 1.4706, 0.8456, 1.4706, 1.4706, 0.8456], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 486, Loss 0.334941\n",
      "Params: %f tensor([0.9219, 0.9219, 0.9546, 0.4219, 0.0219, 0.4546], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4700, 1.4700, 0.8453, 1.4700, 1.4700, 0.8453], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 487, Loss 0.334735\n",
      "Params: %f tensor([0.9218, 0.9218, 0.9545, 0.4218, 0.0218, 0.4545], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4695, 1.4695, 0.8449, 1.4695, 1.4695, 0.8449], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 488, Loss 0.334529\n",
      "Params: %f tensor([0.9216, 0.9216, 0.9544, 0.4216, 0.0216, 0.4544], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4690, 1.4690, 0.8446, 1.4690, 1.4690, 0.8446], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 489, Loss 0.334323\n",
      "Params: %f tensor([0.9215, 0.9215, 0.9543, 0.4215, 0.0215, 0.4543], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4684, 1.4684, 0.8442, 1.4684, 1.4684, 0.8442], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 490, Loss 0.334117\n",
      "Params: %f tensor([0.9213, 0.9213, 0.9543, 0.4213, 0.0213, 0.4543], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4679, 1.4679, 0.8439, 1.4679, 1.4679, 0.8439], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 491, Loss 0.333912\n",
      "Params: %f tensor([0.9212, 0.9212, 0.9542, 0.4212, 0.0212, 0.4542], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4674, 1.4674, 0.8435, 1.4674, 1.4674, 0.8435], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 492, Loss 0.333706\n",
      "Params: %f tensor([0.9210, 0.9210, 0.9541, 0.4210, 0.0210, 0.4541], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4668, 1.4668, 0.8432, 1.4668, 1.4668, 0.8432], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 493, Loss 0.333501\n",
      "Params: %f tensor([0.9209, 0.9209, 0.9540, 0.4209, 0.0209, 0.4540], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4663, 1.4663, 0.8428, 1.4663, 1.4663, 0.8428], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 494, Loss 0.333296\n",
      "Params: %f tensor([0.9207, 0.9207, 0.9539, 0.4207, 0.0207, 0.4539], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4658, 1.4658, 0.8425, 1.4658, 1.4658, 0.8425], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 495, Loss 0.333091\n",
      "Params: %f tensor([0.9206, 0.9206, 0.9538, 0.4206, 0.0206, 0.4538], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4652, 1.4652, 0.8421, 1.4652, 1.4652, 0.8421], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 496, Loss 0.332886\n",
      "Params: %f tensor([0.9204, 0.9204, 0.9538, 0.4204, 0.0204, 0.4538], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4647, 1.4647, 0.8418, 1.4647, 1.4647, 0.8418], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 497, Loss 0.332682\n",
      "Params: %f tensor([0.9203, 0.9203, 0.9537, 0.4203, 0.0203, 0.4537], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4642, 1.4642, 0.8415, 1.4642, 1.4642, 0.8415], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 498, Loss 0.332477\n",
      "Params: %f tensor([0.9201, 0.9201, 0.9536, 0.4201, 0.0201, 0.4536], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4637, 1.4637, 0.8411, 1.4637, 1.4637, 0.8411], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 499, Loss 0.332273\n",
      "Params: %f tensor([0.9200, 0.9200, 0.9535, 0.4200, 0.0200, 0.4535], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4631, 1.4631, 0.8408, 1.4631, 1.4631, 0.8408], dtype=torch.float64)\n",
      "-------------------------------------------------\n",
      "Epoch 500, Loss 0.332069\n",
      "Params: %f tensor([0.9199, 0.9199, 0.9534, 0.4199, 0.0199, 0.4534], dtype=torch.float64)\n",
      "Grad: %f tensor([1.4626, 1.4626, 0.8404, 1.4626, 1.4626, 0.8404], dtype=torch.float64)\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9199, 0.9199, 0.9534, 0.4199, 0.0199, 0.4534], dtype=torch.float64)"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this part I was getting na numbers...I HAD to reduce the learning rate to that level......\n",
    "#rest of the training for LR=0.1,0.01,0.001,0.0001 is done in the following sub-parts of the HW like Problem 1.1,1.2,etc.\n",
    "training_loop(\n",
    "n_epochs = 500,\n",
    "learning_rate = 1e-4,\n",
    "params = torch.tensor([1,1,1,0.5, 0.1, 0.5]),\n",
    "t_u = t_u,\n",
    "t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "f3b6a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_t = np.array(test.area)\n",
    "X2_t = np.array(test.bedrooms)\n",
    "X3_t = np.array(test.bathrooms)\n",
    "X4_t = np.array(test.stories)\n",
    "X5_t = np.array(test.parking)\n",
    "X0_t= np.ones(109)\n",
    "X = np.vstack([X0_t,X1_t,X2_t,X3_t,X4_t,X5_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "3d3cfa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex = [0.5937,  0.5937,  0.7912,  0.0937, -0.3063,  0.2912]\n",
    "Ex = torch.tensor(Ex).reshape(6,1)\n",
    "\n",
    "X = np.vstack([X0_t,X1_t,X2_t,X3_t,X4_t,X5_t])\n",
    "X = X.T\n",
    "X = np.array(X)   \n",
    "x = scaler.fit_transform(X)\n",
    "X= x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "37360946",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(test.price)\n",
    "Y = Y.reshape(109,1)\n",
    "y = scaler.fit_transform(Y)\n",
    "Y = y\n",
    "# Y.reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "fc6f198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: 0.000000\n",
      "Pred: 0.099477\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.030675\n",
      "Pred: 0.263733\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.033742\n",
      "Pred: 0.279905\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.049080\n",
      "Pred: 0.158544\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.049080\n",
      "Pred: 0.235407\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.055215\n",
      "Pred: 0.318185\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.061350\n",
      "Pred: 0.185275\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.061350\n",
      "Pred: 0.143448\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.084356\n",
      "Pred: 0.513555\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.085890\n",
      "Pred: 0.627365\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.085890\n",
      "Pred: 0.237129\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.098160\n",
      "Pred: 0.814931\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.104908\n",
      "Pred: 0.457151\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.107362\n",
      "Pred: 0.090753\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.110429\n",
      "Pred: 0.768546\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.110429\n",
      "Pred: 0.319724\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.116564\n",
      "Pred: 0.499564\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.116564\n",
      "Pred: 0.140043\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.122699\n",
      "Pred: 0.497384\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.122699\n",
      "Pred: 0.032203\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.128221\n",
      "Pred: 0.307646\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.128834\n",
      "Pred: 0.266443\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.128834\n",
      "Pred: 0.369124\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.128834\n",
      "Pred: 0.710253\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.138037\n",
      "Pred: 0.328724\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.141104\n",
      "Pred: 0.327204\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.141104\n",
      "Pred: 0.328340\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.141104\n",
      "Pred: 0.196017\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.141104\n",
      "Pred: 0.353315\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.141104\n",
      "Pred: 0.261169\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.141104\n",
      "Pred: 0.295713\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.147239\n",
      "Pred: 0.149303\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.147239\n",
      "Pred: 0.862503\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.153374\n",
      "Pred: 0.577106\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.153374\n",
      "Pred: -0.040622\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.153374\n",
      "Pred: 0.330556\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.156442\n",
      "Pred: 0.096608\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.156442\n",
      "Pred: 0.216051\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.159509\n",
      "Pred: 0.457408\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.162577\n",
      "Pred: 0.089582\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.165031\n",
      "Pred: 1.015340\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.165644\n",
      "Pred: 0.329673\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.171779\n",
      "Pred: 0.359850\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.177914\n",
      "Pred: 0.303388\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.177914\n",
      "Pred: 0.175524\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.185583\n",
      "Pred: 0.310937\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.187117\n",
      "Pred: 0.547831\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.193252\n",
      "Pred: 0.117337\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.201840\n",
      "Pred: 0.346525\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.201840\n",
      "Pred: 0.923800\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.202454\n",
      "Pred: 0.565731\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.202454\n",
      "Pred: 0.220359\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.202454\n",
      "Pred: 0.342554\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.208589\n",
      "Pred: 0.258207\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.211656\n",
      "Pred: 0.589475\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.214724\n",
      "Pred: 0.710253\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.220245\n",
      "Pred: 0.432594\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.220245\n",
      "Pred: 0.216085\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.223926\n",
      "Pred: 0.105391\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.226994\n",
      "Pred: 0.632600\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.226994\n",
      "Pred: 0.475795\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.233129\n",
      "Pred: 0.358948\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.245399\n",
      "Pred: 0.334195\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.263804\n",
      "Pred: 0.223111\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.263804\n",
      "Pred: 0.627365\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.263804\n",
      "Pred: 0.287224\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.268712\n",
      "Pred: 0.402168\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.276074\n",
      "Pred: 0.535992\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.282209\n",
      "Pred: 0.506717\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.285276\n",
      "Pred: 0.713858\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.291411\n",
      "Pred: 0.964603\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.292638\n",
      "Pred: 0.758522\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.293865\n",
      "Pred: 0.503790\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.294479\n",
      "Pred: 0.367018\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.294479\n",
      "Pred: 0.787813\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.309816\n",
      "Pred: 0.549166\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.322086\n",
      "Pred: 0.762948\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.325153\n",
      "Pred: 0.317740\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.325153\n",
      "Pred: 0.560254\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.325153\n",
      "Pred: 0.847568\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.343558\n",
      "Pred: 0.448225\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.349080\n",
      "Pred: 0.364454\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.349693\n",
      "Pred: 0.419637\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.355828\n",
      "Pred: 0.470837\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.355828\n",
      "Pred: 0.754717\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.361963\n",
      "Pred: 0.812096\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.374233\n",
      "Pred: 0.106737\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.383436\n",
      "Pred: 0.560395\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.385890\n",
      "Pred: 0.425492\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.386503\n",
      "Pred: 0.473250\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.386503\n",
      "Pred: 0.649062\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.396933\n",
      "Pred: 0.475175\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.401840\n",
      "Pred: 0.575553\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.404908\n",
      "Pred: 0.461743\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.414110\n",
      "Pred: 0.955105\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.423313\n",
      "Pred: 0.137183\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.429448\n",
      "Pred: 0.375361\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.429448\n",
      "Pred: 1.306900\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.469325\n",
      "Pred: 0.824713\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.478528\n",
      "Pred: 0.432628\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.487730\n",
      "Pred: 0.489993\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.490798\n",
      "Pred: 0.520892\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.509202\n",
      "Pred: 0.746129\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.509202\n",
      "Pred: 0.510499\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.570552\n",
      "Pred: 0.447246\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.570552\n",
      "Pred: 1.328235\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.592025\n",
      "Pred: 0.505216\n",
      "--------------------------------------------------------------\n",
      "Truth: 0.693252\n",
      "Pred: 0.370691\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "p = 108\n",
    "Wye = np.ones(109)\n",
    "while(p>0):\n",
    "    M = X[p,:]  #13300000\n",
    "    Wye[p] =  np.matmul(M,Ex)\n",
    "    print('Truth: %f'%Y[p])\n",
    "    print('Pred: %f'%Wye[p])\n",
    "    print('--------------------------------------------------------------')\n",
    "    p=p-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "184bd063",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dc47b5c0d0>]"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(Y)\n",
    "pyplot.plot(Wye,'+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "e15c956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, x_train, x_val, y_train, y_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        p_train = model(x_train) \n",
    "        loss_train = loss_fn(p_train, y_train)\n",
    "\n",
    "        p_val = model(x_val) \n",
    "        loss_val = loss_fn(p_val, y_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")\n",
    "seq_model = neu.Sequential(\n",
    "            neu.Linear(6-1, 8),\n",
    "            neu.Tanh(),\n",
    "            neu.Linear(8, 1))\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "6d4f0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning set\n",
    "X1_t = np.array(train.area)\n",
    "X2_t = np.array(train.bedrooms)\n",
    "X3_t = np.array(train.bathrooms)\n",
    "X4_t = np.array(train.stories)\n",
    "X5_t = np.array(train.parking)\n",
    "X0_t= np.ones(436)\n",
    "X = np.vstack([X0_t,X1_t,X2_t,X3_t,X4_t,X5_t])\n",
    "X = X.T\n",
    "X = np.array(X)   \n",
    "x = scaler.fit_transform(X)\n",
    "X_train= x\n",
    "X_train= torch.tensor(X_train)\n",
    "Y = np.array(train.price)\n",
    "Y = Y.reshape(436,1)\n",
    "y = scaler.fit_transform(Y)\n",
    "Y_train = y\n",
    "Y_train = torch.tensor(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "dd7ac16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------#\n",
    "\n",
    "#Test Set\n",
    "X1_t = np.array(test.area)\n",
    "X2_t = np.array(test.bedrooms)\n",
    "X3_t = np.array(test.bathrooms)\n",
    "X4_t = np.array(test.stories)\n",
    "X5_t = np.array(test.parking)\n",
    "X0_t= np.ones(109)\n",
    "X = np.vstack([X0_t,X1_t,X2_t,X3_t,X4_t,X5_t])\n",
    "X = X.T\n",
    "X = np.array(X)   \n",
    "x = scaler.fit_transform(X)\n",
    "X_test= x\n",
    "X_test= torch.tensor(X_test)\n",
    "Y = np.array(test.price)\n",
    "Y = Y.reshape(109,1)\n",
    "y = scaler.fit_transform(Y)\n",
    "Y_test = y\n",
    "Y_test = torch.tensor(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "185a92f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [944]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mneu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [931]\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(n_epochs, optimizer, model, loss_fn, x_train, x_val, y_train, y_val)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_loop\u001b[39m(n_epochs, optimizer, model, loss_fn, x_train, x_val, y_train, y_val):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m         p_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m         loss_train \u001b[38;5;241m=\u001b[39m loss_fn(p_train, y_train)\n\u001b[0;32m      6\u001b[0m         p_val \u001b[38;5;241m=\u001b[39m model(x_val) \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs = 200, optimizer = optimizer, model = seq_model, loss_fn = neu.MSELoss(), \n",
    "              x_train = X_train, x_val = X_test, y_train = Y_train, y_val = Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
